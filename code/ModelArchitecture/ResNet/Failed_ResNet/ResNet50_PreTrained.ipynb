{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77441ad-99ed-4a60-a710-ed5f90778fef",
   "metadata": {},
   "source": [
    "### ResNet50 Trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b65e0-6e1e-4465-b8e3-6bb02d225f0c",
   "metadata": {},
   "source": [
    "### Initialize Notebook & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5cf8d2-e592-4314-9f9d-f9034cbf1b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 22:43:17.608053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-13 22:43:17.622750: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-13 22:43:17.627368: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-13 22:43:17.639013: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled. Checking for available GPUs...\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "\n",
      "Verifying TensorFlow and PyTorch CUDA setup...\n",
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: True\n",
      "Num GPUs Available: 1\n",
      "\n",
      "Keras version: 3.6.0\n",
      "\n",
      "End checks and initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734129799.567599  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734129799.612493  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734129799.615967  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734129799.621336  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734129799.624778  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734129799.628068  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734129799.828330  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734129799.830433  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734129799.832356  630556 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 22:43:19.834246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13312 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import helper as hp \n",
    "hp.initialize_notebook() # initialize with GPU enabled  \n",
    "# hp.initialize_notebook(False) # to disable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350726ef-1106-4639-b36d-bf68e7aa74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras\n",
    "# Import DL libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras import layers, models, Model, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.callbacks import TensorBoard \n",
    "\n",
    "# Suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Import image libraries\n",
    "from skimage import transform\n",
    "import tifffile as tiff\n",
    "\n",
    "# Appends current working dir\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "\n",
    "# Import custom preprocessing class\n",
    "from imc_preprocessing import IMCPreprocessor\n",
    "\n",
    "# Import Stratified Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d03d7d-be22-491c-915e-f9ebff1f54b1",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ede3c32-a3d7-4e01-b26a-57eb0b5b6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (if needed)\n",
    "def preprocessing(image, transpose=True, normalize=True) -> np.ndarray:\n",
    "    if transpose:\n",
    "        return np.transpose(image, (1, 2, 0))\n",
    "    if normalize:\n",
    "        return IMCPreprocessor.normalize_multichannel_image(image)\n",
    "\n",
    "# Load images\n",
    "def load_image(image_path) -> np.ndarray:\n",
    "    image = tiff.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    return image\n",
    "\n",
    "\n",
    "# Define a function to create a list of images from files within a folder \n",
    "def image_list(image_dir):\n",
    "    # List all files in the directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]  \n",
    "    # Initialize a list to store the images\n",
    "    images = []\n",
    "    # Loop through each file and read the image\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        image = load_image(image_path)\n",
    "        images.append(image)        \n",
    "    return images \n",
    "\n",
    "# Converting to one hot\n",
    "def convert_to_one_hot(y, classes):\n",
    "    return np.eye(classes)[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a5e4f-4da8-4210-ad97-02ec4857abbe",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "#### Preprocessing and Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3167372b-5c56-4c9f-a334-7fe94c2dd138",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/home/jupyter-luvogt/Final_Project_LR/IMC_images' \n",
    "metadata_dir = '/home/jupyter-luvogt/Final_Project_LR/metadata.csv' \n",
    "panel_dir = '/home/jupyter-luvogt/Final_Project_LR/panel.csv' \n",
    "os.listdir(images_dir)[:5] # Get first five images\n",
    "\n",
    "# Load images\n",
    "images = image_list(images_dir)\n",
    "images = np.array(images)\n",
    "\n",
    "# load labels\n",
    "metadata = pd.read_csv(metadata_dir)\n",
    "PDL1_score = metadata[\"PDL1_score\"]\n",
    "\n",
    "# Shape PDL1\n",
    "PDL1_score = PDL1_score.tolist()\n",
    "PDL1_score = np.array(PDL1_score)\n",
    "\n",
    "# Transpose and Normalize images\n",
    "images_preproc = [preprocessing(i, transpose = True, normalize = False) for i in images]\n",
    "images_preproc = [preprocessing(i, transpose = False, normalize = True) for i in images_preproc]\n",
    "images_preproc = np.array(images_preproc)\n",
    "\n",
    "# Extract channel information\n",
    "panel_df = pd.read_csv(panel_dir)\n",
    "channel_names = dict(zip(panel_df['clean_target'].to_list(), panel_df['channel'].to_list()))\n",
    "\n",
    "# Filter out Xe131, Xe134 and Ba138 = Noise channels (OPTIONAL) \n",
    "channel_names_new = [x for x in list(channel_names.values()) if x not in [\"Xe131\", \"Xe134\", \"Ba138\"]]\n",
    "images_preproc_drop = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "images_preproc_drop = np.array(images_preproc_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c26ff9-1878-4cd6-98e9-18d84899a49e",
   "metadata": {},
   "source": [
    "### ResNet50 Model: Trained directly here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d214a9c-5f8c-4afa-b34d-acba9c11f840",
   "metadata": {},
   "source": [
    "#### ResNet50 Model: 3 Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7f723-8027-4f25-ad56-84c195bc2afc",
   "metadata": {},
   "source": [
    "Approach: Select biological relevant channels that correspond or are associated with PDL1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f57187-d166-4ee9-87a2-b2822848edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose biological relevant channels\n",
    "channel_names_new = [\"Gd160\", \"Eu153\", \"Gd155\"]\n",
    "images_preproc_drop_3 = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "images_preproc_drop_3 = np.array(images_preproc_drop_3)\n",
    "\n",
    "channels_preproc_drop_3 = channel_names_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283d430-eb33-40ba-8ce3-af0ab813bda0",
   "metadata": {},
   "source": [
    "Create unbalanced (but with stratified) training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcd9e35-a4f8-4292-9719-e32301151daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 56\n",
    "X = images_preproc_drop_3\n",
    "y = PDL1_score\n",
    "train_size = 0.6\n",
    "val_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "\n",
    "# Create a StratifiedShuffleSplit for train/test split\n",
    "sss_train_test = StratifiedShuffleSplit(n_splits=1, test_size=(val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# First split: Train and remaining (validation + test)\n",
    "for train_index, remaining_index in sss_train_test.split(X, y):\n",
    "    X_train, X_remaining = X[train_index], X[remaining_index]\n",
    "    y_train, y_remaining = y[train_index], y[remaining_index]\n",
    "\n",
    "# Create a StratifiedShuffleSplit for validation/test split on remaining data\n",
    "sss_val_test = StratifiedShuffleSplit(n_splits=1, test_size=test_size / (val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# Second split: Validation and Test\n",
    "for val_index, test_index in sss_val_test.split(X_remaining, y_remaining):\n",
    "    X_val, X_test = X_remaining[val_index], X_remaining[test_index]\n",
    "    y_val, y_test = y_remaining[val_index], y_remaining[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb9e96-83de-4774-802d-e8ed6390e6ce",
   "metadata": {},
   "source": [
    "Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976e1b3-9a3f-495e-b3e3-3ee076227e13",
   "metadata": {},
   "source": [
    "Define CONSTANTS and do One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c5b483e-b951-4b99-af09-a8dbab68d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "CLASSES = 2\n",
    "y_train_one_hot = convert_to_one_hot(y_train, CLASSES)\n",
    "y_test_one_hot = convert_to_one_hot(y_test, CLASSES)\n",
    "y_val_one_hot = convert_to_one_hot(y_val, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56165598-bc31-4817-a6bc-cf7f1d2a5804",
   "metadata": {},
   "source": [
    "Define Blocks and ResNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1623e1-9fd7-4de6-941b-8d764c333cdb",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b9fee88-2f3f-4ec7-944b-dfb4920ff55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734129951.949765  630641 service.cc:146] XLA service 0x7f7e240038b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734129951.949798  630641 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-13 22:45:52.668152: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-13 22:45:55.344978: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "2024-12-13 22:46:00.112896: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1734129976.726975  630641 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.5472 - loss: 1.0097 - val_accuracy: 0.6396 - val_loss: 52.1065\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 260ms/step - accuracy: 0.6221 - loss: 0.7164 - val_accuracy: 0.6396 - val_loss: 153.5427\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 263ms/step - accuracy: 0.6170 - loss: 0.6549 - val_accuracy: 0.3604 - val_loss: 55.2975\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 265ms/step - accuracy: 0.6489 - loss: 0.6663 - val_accuracy: 0.3604 - val_loss: 1.4350\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 266ms/step - accuracy: 0.6306 - loss: 0.6343 - val_accuracy: 0.6396 - val_loss: 0.6663\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 268ms/step - accuracy: 0.6619 - loss: 0.6037 - val_accuracy: 0.6396 - val_loss: 4.6068\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 270ms/step - accuracy: 0.7389 - loss: 0.5359 - val_accuracy: 0.6396 - val_loss: 9.7457\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 0.8870 - loss: 0.3028 - val_accuracy: 0.6396 - val_loss: 0.8373\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 0.8939 - loss: 0.2549 - val_accuracy: 0.6396 - val_loss: 2.9240\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 276ms/step - accuracy: 0.9345 - loss: 0.1692 - val_accuracy: 0.6396 - val_loss: 1.0720\n",
      "\n",
      "Elapsed time: 151.06727123260498 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build Pre Trained ResNet50\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "resnet50 = ResNet50(weights=\"imagenet\", include_top = True) # Include fully connected layers\n",
    "# Replacing the final classification Layer\n",
    "num_classes = 2\n",
    "x = resnet50.layers[-2].output # Accessing the final classification layer\n",
    "new_output = Dense(num_classes, activation = \"softmax\")(x)\n",
    "# for layer in resnet50.layers:\n",
    "#     layer.trainable = False\n",
    "# new_output.trainable = True\n",
    "resnet_new = Model(inputs = resnet50.input, outputs = new_output)\n",
    "\n",
    "\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1e-3\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "resnet_new.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Apply TensorBoard\n",
    "# # define the logs folder \n",
    "# log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # Define TensorBoard Callback\n",
    "# tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 32\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet50_trained = resnet_new.fit(X_train, y_train_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val_one_hot))\n",
    "                                      # callbacks=tb_callback)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25e11898-a3da-428f-9a8f-89e23d1ba34b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 461ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557],\n",
       "       [0.74560446, 0.25439557]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781dbf53-e736-4869-b47b-92626b13635d",
   "metadata": {},
   "source": [
    "INTERESTING: validation accuracy constantly 0.6396 (or 0.3604) indicates that model only predicts PDL1 == 0 as this is the distribution in our unbalanced validation set\n",
    "\n",
    "Indication: Overfitting\n",
    "\n",
    "Possible sources for lack of generalization: \n",
    "\n",
    "    - Lack of Regularization\n",
    "    - Unbalanced Dataset\n",
    "    - Overly complex model\n",
    "    - Add more channels because 3 channels don't contain enough information for generalization? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d3052-49a2-4b69-8989-5e1f5cab32ab",
   "metadata": {},
   "source": [
    "### ResNet50 Model: 3 Channels & L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ac15f4b-54de-49c1-9de3-823174f080f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.5646 - loss: 0.7581 - val_accuracy: 0.6396 - val_loss: 0.6993\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 263ms/step - accuracy: 0.9764 - loss: 0.3228 - val_accuracy: 0.6396 - val_loss: 0.7026\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 0.1097 - val_accuracy: 0.6396 - val_loss: 0.7171\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0590 - val_accuracy: 0.6396 - val_loss: 0.7530\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0476 - val_accuracy: 0.6396 - val_loss: 0.8173\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.0458 - val_accuracy: 0.6396 - val_loss: 0.9357\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 1.0000 - loss: 0.0440 - val_accuracy: 0.6396 - val_loss: 0.9181\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 275ms/step - accuracy: 1.0000 - loss: 0.0431 - val_accuracy: 0.6396 - val_loss: 0.9242\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 0.0419 - val_accuracy: 0.6396 - val_loss: 0.9755\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 277ms/step - accuracy: 1.0000 - loss: 0.0410 - val_accuracy: 0.6396 - val_loss: 1.1068\n",
      "\n",
      "Elapsed time: 110.72134017944336 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build Pre Trained ResNet50 with L2 Regularization\n",
    "from keras.applications import ResNet50\n",
    "from keras.regularizers import l2\n",
    "\n",
    "resnet50 = ResNet50(weights=\"imagenet\", include_top = True) # Include fully connected layers\n",
    "# Replacing the final classification Layer\n",
    "num_classes = 2\n",
    "x = resnet50.layers[-2].output # Accessing the final classification layer\n",
    "new_output = Dense(num_classes, activation = \"softmax\", kernel_regularizer=l2(0.01))(x)\n",
    "# for layer in resnet50.layers:\n",
    "#     layer.trainable = False\n",
    "# new_output.trainable = True\n",
    "resnet_new = Model(inputs = resnet50.input, outputs = new_output)\n",
    "\n",
    "\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "resnet_new.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Apply TensorBoard\n",
    "# # define the logs folder \n",
    "# log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # Define TensorBoard Callback\n",
    "# tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 32\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet50_trained = resnet_new.fit(X_train, y_train_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val_one_hot))\n",
    "                                      # callbacks=tb_callback)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7f12b-b20c-4e30-853d-505e2d4f28c9",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Problem persists when Regularization added to last classification layer --> use manually constructed ResNet to experiment with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5765f2-76c0-4abe-a032-26de74a2ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BME342 Env",
   "language": "python",
   "name": "bme342_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
