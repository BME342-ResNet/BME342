{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77441ad-99ed-4a60-a710-ed5f90778fef",
   "metadata": {},
   "source": [
    "### ResNet18 Trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b65e0-6e1e-4465-b8e3-6bb02d225f0c",
   "metadata": {},
   "source": [
    "### Initialize Notebook & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5cf8d2-e592-4314-9f9d-f9034cbf1b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 13:06:41.329264: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-15 13:06:41.367679: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-15 13:06:41.377383: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-15 13:06:41.675334: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled. Checking for available GPUs...\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "\n",
      "Verifying TensorFlow and PyTorch CUDA setup...\n",
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: True\n",
      "Num GPUs Available: 1\n",
      "\n",
      "Keras version: 3.6.0\n",
      "\n",
      "End checks and initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734268014.160985  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734268014.969140  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734268014.974488  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734268014.981592  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734268014.984899  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734268014.988089  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734268015.210929  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734268015.212988  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734268015.214890  667231 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-15 13:06:55.216749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13312 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import helper as hp \n",
    "hp.initialize_notebook() # initialize with GPU enabled  \n",
    "# hp.initialize_notebook(False) # to disable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350726ef-1106-4639-b36d-bf68e7aa74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras\n",
    "# Import DL libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras import layers, models, Model, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.callbacks import TensorBoard \n",
    "\n",
    "# Suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Import image libraries\n",
    "from skimage import transform\n",
    "import tifffile as tiff\n",
    "\n",
    "# Appends current working dir\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "\n",
    "# Import custom preprocessing class\n",
    "from imc_preprocessing import IMCPreprocessor\n",
    "\n",
    "# Import Stratified Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d03d7d-be22-491c-915e-f9ebff1f54b1",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ede3c32-a3d7-4e01-b26a-57eb0b5b6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (if needed)\n",
    "def preprocessing(image, transpose=True, normalize=True) -> np.ndarray:\n",
    "    if transpose:\n",
    "        return np.transpose(image, (1, 2, 0))\n",
    "    if normalize:\n",
    "        return IMCPreprocessor.normalize_multichannel_image(image)\n",
    "\n",
    "# Load images\n",
    "def load_image(image_path) -> np.ndarray:\n",
    "    image = tiff.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    return image\n",
    "\n",
    "\n",
    "# Define a function to create a list of images from files within a folder \n",
    "def image_list(image_dir):\n",
    "    # List all files in the directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]  \n",
    "    # Initialize a list to store the images\n",
    "    images = []\n",
    "    image_files_list = []\n",
    "    # Loop through each file and read the image\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        image = load_image(image_path)\n",
    "        images.append(image)  \n",
    "        image_files_list.append(image_file)\n",
    "    return [images, image_files_list] \n",
    "\n",
    "def image_list_and_PDL1(image_dir):\n",
    "    # List all files in the directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]  \n",
    "    # Initialize a list to store the images\n",
    "    images = []\n",
    "    PDL1 = []\n",
    "    image_files_list = []\n",
    "    # Loop through each file and read the image\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        image = load_image(image_path)\n",
    "        images.append(image)  \n",
    "        image_files_list.append(image_file)\n",
    "        PDL1.append(metadata[metadata[\"sample_id\"] == image_file.strip(\".tiff\")][\"PDL1_score\"])\n",
    "    return [images, image_files_list, PDL1] \n",
    "\n",
    "# Converting to one hot\n",
    "def convert_to_one_hot(y, classes):\n",
    "    return np.eye(classes)[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a5e4f-4da8-4210-ad97-02ec4857abbe",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "#### Preprocessing and Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3167372b-5c56-4c9f-a334-7fe94c2dd138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# images_dir = '/home/jupyter-luvogt/Final_Project_LR/IMC_images' \n",
    "# metadata_dir = '/home/jupyter-luvogt/Final_Project_LR/metadata.csv' \n",
    "# panel_dir = '/home/jupyter-luvogt/Final_Project_LR/panel.csv' \n",
    "# os.listdir(images_dir)[:5] # Get first five images\n",
    "\n",
    "# # Load images\n",
    "# images = image_list(images_dir)[0]\n",
    "# images = np.array(images)\n",
    "\n",
    "# # Load Image_paths\n",
    "# image_files = image_list(images_dir)[1] # Define image files for debugging\n",
    "# image_files = np.array(image_files)\n",
    "# # load labels\n",
    "# metadata = pd.read_csv(metadata_dir)\n",
    "# PDL1_score = metadata[\"PDL1_score\"]\n",
    "\n",
    "# # Shape PDL1\n",
    "# PDL1_score = PDL1_score.tolist()\n",
    "# PDL1_score = np.array(PDL1_score)\n",
    "\n",
    "# # Transpose and Normalize images\n",
    "# images_preproc = [preprocessing(i, transpose = True, normalize = False) for i in images]\n",
    "# images_preproc = [preprocessing(i, transpose = False, normalize = True) for i in images_preproc]\n",
    "# images_preproc = np.array(images_preproc)\n",
    "\n",
    "# # Extract channel information\n",
    "# panel_df = pd.read_csv(panel_dir)\n",
    "# channel_names = dict(zip(panel_df['clean_target'].to_list(), panel_df['channel'].to_list()))\n",
    "\n",
    "# # Filter out Xe131, Xe134 and Ba138 = Noise channels (OPTIONAL) \n",
    "# channel_names_new = [x for x in list(channel_names.values()) if x not in [\"Xe131\", \"Xe134\", \"Ba138\"]]\n",
    "# images_preproc_drop = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "# images_preproc_drop = np.array(images_preproc_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c26ff9-1878-4cd6-98e9-18d84899a49e",
   "metadata": {},
   "source": [
    "### ResNet18 Model: Trained directly here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d214a9c-5f8c-4afa-b34d-acba9c11f840",
   "metadata": {},
   "source": [
    "#### ResNet18 Model: 3 Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7f723-8027-4f25-ad56-84c195bc2afc",
   "metadata": {},
   "source": [
    "Approach: Select biological relevant channels that correspond or are associated with PDL1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f57187-d166-4ee9-87a2-b2822848edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose 3 biological relevant channels\n",
    "# channel_names_new = [\"Gd160\", \"Eu153\", \"Gd155\"]\n",
    "# images_preproc_drop_3 = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "# images_preproc_drop_3 = np.array(images_preproc_drop_3)\n",
    "\n",
    "# channels_preproc_drop_3 = channel_names_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283d430-eb33-40ba-8ce3-af0ab813bda0",
   "metadata": {},
   "source": [
    "Create unbalanced (but with stratified) training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcd9e35-a4f8-4292-9719-e32301151daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_seed = 56\n",
    "# X = images_preproc_drop # Change here if you want 43 channels or 3 channels (images_preproc_drop_3)\n",
    "# y = PDL1_score\n",
    "# train_size = 0.6\n",
    "# val_size = 0.2\n",
    "# test_size = 0.2\n",
    "\n",
    "\n",
    "# # Create a StratifiedShuffleSplit for train/test split\n",
    "# sss_train_test = StratifiedShuffleSplit(n_splits=1, test_size=(val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# # First split: Train and remaining (validation + test)\n",
    "# for train_index, remaining_index in sss_train_test.split(X, y):\n",
    "#     X_train, X_remaining = X[train_index], X[remaining_index]\n",
    "#     y_train, y_remaining = y[train_index], y[remaining_index]\n",
    "\n",
    "# # Create a StratifiedShuffleSplit for validation/test split on remaining data\n",
    "# sss_val_test = StratifiedShuffleSplit(n_splits=1, test_size=test_size / (val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# # Second split: Validation and Test\n",
    "# for val_index, test_index in sss_val_test.split(X_remaining, y_remaining):\n",
    "#     X_val, X_test = X_remaining[val_index], X_remaining[test_index]\n",
    "#     y_val, y_test = y_remaining[val_index], y_remaining[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976e1b3-9a3f-495e-b3e3-3ee076227e13",
   "metadata": {},
   "source": [
    "Import One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5b483e-b951-4b99-af09-a8dbab68d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "# CLASSES = 2\n",
    "# y_train_one_hot = convert_to_one_hot(y_train, CLASSES)\n",
    "# y_test_one_hot = convert_to_one_hot(y_test, CLASSES)\n",
    "# y_val_one_hot = convert_to_one_hot(y_val, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56165598-bc31-4817-a6bc-cf7f1d2a5804",
   "metadata": {},
   "source": [
    "Define Blocks and ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d77d4e7-e328-467e-8904-685284dbc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "def identity_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3]):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1623e1-9fd7-4de6-941b-8d764c333cdb",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b9fee88-2f3f-4ec7-944b-dfb4920ff55a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_649715/1672001475.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mCHANNELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mCLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mblock_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Build Network Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_ResNet18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mROWS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Compile Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ml_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_649715/2572530429.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(shape, classes, block_layers)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Step 1 (Setup Input Layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Step 2 (Initial Conv layer along with maxPool)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;31m################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;31m# 4. Call build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# 5. Infer training value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, call_spec)\u001b[0m\n\u001b[1;32m   1361\u001b[0m                 \u001b[0mshapes_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshapes_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m                 \u001b[0mcall_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m                 \u001b[0mclass_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mshapes_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m             \u001b[0;31m# Check input spec again (after build, since self.input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0;31m# may have been updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_build_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbuild_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0moriginal_build_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;31m# Record build config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_build_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_shapes_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# compute_output_shape contains some validation logic for the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# shape, and make sure the output shape has all positive dimensions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         self._kernel = self.add_weight(\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kernel\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, name)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                 \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"zeros\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             variable = backend.Variable(\n\u001b[0m\u001b[1;32m    542\u001b[0m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, initializer)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         self._value = tf.Variable(\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtraceback_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_variable_call\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m       \u001b[0mvariable_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvariable_call\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape, experimental_enable_variable_lifting, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[0;31m# Reset `aggregation` that is explicitly set as `None` to the enum NONE.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(**kws)\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(next_creator, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_variable_ops\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m   return resource_variable_ops.default_variable_creator_v2(\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0mnext_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   experimental_enable_variable_lifting = kwargs.get(\n\u001b[1;32m    355\u001b[0m       \u001b[0;34m\"experimental_enable_variable_lifting\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m   return ResourceVariable(\n\u001b[0m\u001b[1;32m    358\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_variable_call\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0mvariable_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvariable_call\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape, handle, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m   1869\u001b[0m                              \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m                              \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m                              \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m       self._init_from_args(\n\u001b[0m\u001b[1;32m   1874\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape, experimental_enable_variable_lifting)\u001b[0m\n\u001b[1;32m   2053\u001b[0m                 \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mhandle_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attr_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2057\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2058\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_uid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_uid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/initializers/random_initializers.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             return random.uniform(\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/random.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cast_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     return tf.random.stateless_uniform(\n\u001b[1;32m     35\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/random.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Ref: https://www.tensorflow.org/api_docs/python/tf/random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloormod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4174\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FloorMod\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4175\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4176\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4177\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4178\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4179\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4180\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m       _result = _dispatcher_for_floor_mod(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ROWS = 224\n",
    "# COLS = 224\n",
    "# CHANNELS = 43\n",
    "# CLASSES = 2\n",
    "# block_layers = [2,2,2,2]\n",
    "# # Build Network Graph \n",
    "# model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "\n",
    "# # Compile Model \n",
    "# l_rate = 1.e-4\n",
    "# opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "# model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Apply TensorBoard\n",
    "# # # define the logs folder \n",
    "# # log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # # Define TensorBoard Callback\n",
    "# # tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# # Train Model \n",
    "# batch = 32\n",
    "# epochs = 10\n",
    "# start_time = time.time()\n",
    "\n",
    "# history_ResNet18 = model_ResNet18.fit(X_train, y_train_one_hot, \n",
    "#                                       epochs = epochs, batch_size = batch, \n",
    "#                                       validation_data = (X_val, y_val_one_hot))\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32bd7979-acb2-4500-bcc6-fddc4971f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n"
     ]
    }
   ],
   "source": [
    "# t = model_ResNet18.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31f82817-9124-4d5d-9497-d1b7aa762b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.6339 - loss: 0.7278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.672294557094574, 0.6593220233917236]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_ResNet18.evaluate(X_train, y_train_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e8770c-35e1-4e6c-b7a4-84983ff46ef6",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Even with ResNet18, the model still seems to only predict the majority class. Thus, in order to try to address this issue, we will first attack the problem from the unbalanced data set problem side: \n",
    "\n",
    "    - Introduce Class Weights\n",
    "    - Create Balanced data set\n",
    "    - Increase minority class with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca3e8a-cf9f-4aaa-a9f2-b021fe7c4ed8",
   "metadata": {},
   "source": [
    "### ResNet10: Introducing Class Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9fe5f-0381-4c05-b71f-698bc97ed340",
   "metadata": {},
   "source": [
    "Model Class Weights Calculation\n",
    "\n",
    "And even reduce Model size to ResNet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c599727-e25e-46df-a49b-34f9ddb214f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import class_weight\n",
    "# weights = class_weight.compute_class_weight(\"balanced\", classes = np.unique(y_train), y = y_train)\n",
    "# class_weights = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67de9872-7bce-40a4-bfd7-e7409a8b26f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 782ms/step - accuracy: 0.4883 - loss: 1.0176 - val_accuracy: 0.3604 - val_loss: 0.7011\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - accuracy: 0.5340 - loss: 0.7055 - val_accuracy: 0.6396 - val_loss: 0.6847\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - accuracy: 0.6233 - loss: 0.6568 - val_accuracy: 0.6396 - val_loss: 0.6741\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - accuracy: 0.6122 - loss: 0.6719 - val_accuracy: 0.6396 - val_loss: 0.6804\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - accuracy: 0.6652 - loss: 0.6170 - val_accuracy: 0.6396 - val_loss: 0.6734\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 0.7744 - loss: 0.5516 - val_accuracy: 0.6396 - val_loss: 0.6698\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - accuracy: 0.8152 - loss: 0.5221 - val_accuracy: 0.6396 - val_loss: 0.6656\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - accuracy: 0.8035 - loss: 0.4452 - val_accuracy: 0.6396 - val_loss: 0.6566\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - accuracy: 0.8916 - loss: 0.3696 - val_accuracy: 0.6396 - val_loss: 0.6864\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 163ms/step - accuracy: 0.9231 - loss: 0.2977 - val_accuracy: 0.6396 - val_loss: 0.6818\n",
      "\n",
      "Elapsed time: 72.25934076309204 seconds\n"
     ]
    }
   ],
   "source": [
    "# ROWS = 224\n",
    "# COLS = 224\n",
    "# CHANNELS = 43\n",
    "# CLASSES = 2\n",
    "# block_layers = [1,1,1,1]\n",
    "# # Build Network Graph \n",
    "# model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "\n",
    "# # Compile Model \n",
    "# l_rate = 1.e-4\n",
    "# opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "# model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Apply TensorBoard\n",
    "# # # define the logs folder \n",
    "# # log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # # Define TensorBoard Callback\n",
    "# # tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# # Train Model \n",
    "# batch = 32\n",
    "# epochs = 10\n",
    "# start_time = time.time()\n",
    "\n",
    "# history_ResNet18 = model_ResNet18.fit(X_train, y_train_one_hot, \n",
    "#                                       epochs = epochs, batch_size = batch, \n",
    "#                                       validation_data = (X_val, y_val_one_hot), \n",
    "#                                       class_weight = class_weights)\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e5bbd97-49a0-4984-938e-bdf302d79ab5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 154ms/step\n",
      "[[0.9151241  0.08487583]\n",
      " [0.8824722  0.11752776]\n",
      " [0.9190049  0.08099506]\n",
      " [0.8523949  0.14760512]\n",
      " [0.903726   0.09627395]\n",
      " [0.8987082  0.1012918 ]\n",
      " [0.87999773 0.12000225]\n",
      " [0.92008114 0.07991882]\n",
      " [0.90192103 0.09807896]\n",
      " [0.9014896  0.09851039]\n",
      " [0.8976786  0.10232136]\n",
      " [0.87083733 0.12916267]\n",
      " [0.8840908  0.1159092 ]\n",
      " [0.90777695 0.09222302]\n",
      " [0.9016646  0.09833534]\n",
      " [0.88322604 0.11677395]\n",
      " [0.89981246 0.10018753]\n",
      " [0.86775917 0.1322408 ]\n",
      " [0.8882554  0.11174451]\n",
      " [0.8954403  0.10455975]\n",
      " [0.85610664 0.14389338]\n",
      " [0.8988902  0.10110982]\n",
      " [0.8975536  0.10244637]\n",
      " [0.8974461  0.10255393]\n",
      " [0.88729185 0.11270811]\n",
      " [0.9015776  0.09842241]\n",
      " [0.8887577  0.11124229]\n",
      " [0.9019362  0.09806384]\n",
      " [0.89208215 0.10791782]\n",
      " [0.8880185  0.11198147]\n",
      " [0.89878786 0.10121211]\n",
      " [0.8891496  0.11085043]\n",
      " [0.893966   0.10603395]\n",
      " [0.8838623  0.11613767]\n",
      " [0.904973   0.09502705]\n",
      " [0.8793694  0.12063062]\n",
      " [0.90389097 0.09610905]\n",
      " [0.8961733  0.10382664]\n",
      " [0.8936265  0.10637353]\n",
      " [0.9030336  0.09696636]\n",
      " [0.9085895  0.09141051]\n",
      " [0.8771124  0.12288759]\n",
      " [0.8946754  0.10532456]\n",
      " [0.884099   0.11590099]\n",
      " [0.90902925 0.09097078]\n",
      " [0.79196185 0.20803815]\n",
      " [0.8749016  0.12509844]\n",
      " [0.9031017  0.0968983 ]\n",
      " [0.9094165  0.09058347]\n",
      " [0.9004804  0.09951963]\n",
      " [0.8916037  0.10839625]\n",
      " [0.8723168  0.12768324]\n",
      " [0.8934471  0.10655285]\n",
      " [0.8914845  0.10851548]\n",
      " [0.90759754 0.09240248]\n",
      " [0.9011087  0.09889133]\n",
      " [0.89926034 0.10073971]\n",
      " [0.9095242  0.09047578]\n",
      " [0.8913389  0.10866112]\n",
      " [0.88900596 0.11099402]\n",
      " [0.9192557  0.08074428]\n",
      " [0.8882085  0.11179145]\n",
      " [0.8936529  0.10634714]\n",
      " [0.89096725 0.10903272]\n",
      " [0.86630815 0.13369189]\n",
      " [0.8935428  0.10645714]\n",
      " [0.8812613  0.11873876]\n",
      " [0.8962331  0.10376693]\n",
      " [0.88897675 0.11102321]\n",
      " [0.91007537 0.0899246 ]\n",
      " [0.90512717 0.0948728 ]\n",
      " [0.8841268  0.11587325]\n",
      " [0.90026665 0.09973338]\n",
      " [0.9014602  0.09853985]\n",
      " [0.8855002  0.11449981]\n",
      " [0.9068333  0.09316672]\n",
      " [0.8541881  0.14581193]\n",
      " [0.91313374 0.08686629]\n",
      " [0.8765159  0.12348408]\n",
      " [0.870352   0.12964794]\n",
      " [0.8954766  0.10452342]\n",
      " [0.88079935 0.11920068]\n",
      " [0.9082278  0.09177221]\n",
      " [0.853052   0.14694797]\n",
      " [0.90231127 0.09768875]\n",
      " [0.91346693 0.08653305]\n",
      " [0.89215803 0.10784198]\n",
      " [0.8895045  0.11049552]\n",
      " [0.90295964 0.09704033]\n",
      " [0.87584925 0.12415076]\n",
      " [0.9046785  0.09532146]\n",
      " [0.87703097 0.12296908]\n",
      " [0.8611462  0.13885382]\n",
      " [0.910785   0.08921494]\n",
      " [0.9238225  0.0761775 ]\n",
      " [0.8703349  0.12966508]\n",
      " [0.88828236 0.1117176 ]\n",
      " [0.9019317  0.09806827]\n",
      " [0.88994735 0.11005261]]\n"
     ]
    }
   ],
   "source": [
    "# t = model_ResNet18.predict(X_test)\n",
    "# print(t[1:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e05a0b2-a39c-4b1e-9c9e-54ca8fe96784",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "    - Introducing Class Weights: No difference, model overfits and only predicts majority class, even with ResNet10 (less complex model)\n",
    "    - NOW: Try Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9093457-cf76-4589-a6db-01e2e1549ff8",
   "metadata": {},
   "source": [
    "### ResNet10: Downsampling of Majority Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21b3d7-e379-4068-8f2b-5f9d300e31ef",
   "metadata": {},
   "source": [
    "Downsampling of Majority Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e883e90-a173-4c36-adf4-f30fd72edf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import imblearn\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# # Define Undersampling balancing method\n",
    "# balancer = RandomUnderSampler(random_state = 42) # Undersampling majority class\n",
    "\n",
    "# images_flat = images_preproc_drop.reshape(images_preproc_drop.shape[0], -1) # Reshape images for balancer\n",
    "# images_preproc_drop_resampled, PDL1_resampled = balancer.fit_resample(images_flat, PDL1_score) # resample (Undersampling)\n",
    "\n",
    "# images_preproc_drop_resampled = images_preproc_drop_resampled.reshape(-1, *images_preproc_drop.shape[1:]) # Re shape the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ca9eb1-6751-43c7-b1ee-08607d5eff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_seed = 56\n",
    "# X = images_preproc_drop_resampled # Change here if you want 43 channels or 3 channels (images_preproc_drop_3)\n",
    "# y = PDL1_resampled\n",
    "# train_size = 0.6\n",
    "# val_size = 0.2\n",
    "# test_size = 0.2\n",
    "\n",
    "\n",
    "# # Create a StratifiedShuffleSplit for train/test split\n",
    "# sss_train_test = StratifiedShuffleSplit(n_splits=1, test_size=(val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# # First split: Train and remaining (validation + test)\n",
    "# for train_index, remaining_index in sss_train_test.split(X, y):\n",
    "#     X_train, X_remaining = X[train_index], X[remaining_index]\n",
    "#     y_train, y_remaining = y[train_index], y[remaining_index]\n",
    "\n",
    "# # Create a StratifiedShuffleSplit for validation/test split on remaining data\n",
    "# sss_val_test = StratifiedShuffleSplit(n_splits=1, test_size=test_size / (val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# # Second split: Validation and Test\n",
    "# for val_index, test_index in sss_val_test.split(X_remaining, y_remaining):\n",
    "#     X_val, X_test = X_remaining[val_index], X_remaining[test_index]\n",
    "#     y_val, y_test = y_remaining[val_index], y_remaining[test_index]\n",
    "\n",
    "# CLASSES = 2\n",
    "# y_train_one_hot = convert_to_one_hot(y_train, CLASSES)\n",
    "# y_test_one_hot = convert_to_one_hot(y_test, CLASSES)\n",
    "# y_val_one_hot = convert_to_one_hot(y_val, CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a4d344e-d3cc-42ff-8e3a-ae24ff9f747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 19:43:12.846543: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3685126144 exceeds 10% of free system memory.\n",
      "2024-12-14 19:43:14.582333: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3685126144 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734205401.171647  652570 service.cc:146] XLA service 0x7fdf78003800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734205401.171703  652570 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-14 19:43:21.307176: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-14 19:43:21.893100: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "I0000 00:00:1734205412.392863  652570 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.4951 - loss: 1.1123 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 2/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - accuracy: 0.8633 - loss: 0.4701 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
      "Epoch 3/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - accuracy: 0.9943 - loss: 0.2471 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
      "Epoch 4/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.1279 - val_accuracy: 0.4789 - val_loss: 0.6933\n",
      "Epoch 5/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0508 - val_accuracy: 0.5000 - val_loss: 0.6981\n",
      "Epoch 6/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0263 - val_accuracy: 0.5000 - val_loss: 0.7128\n",
      "Epoch 7/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.5000 - val_loss: 0.7075\n",
      "Epoch 8/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.5000 - val_loss: 0.7253\n",
      "Epoch 9/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.5000 - val_loss: 0.7291\n",
      "Epoch 10/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.5000 - val_loss: 0.7486\n",
      "\n",
      "Elapsed time: 57.45630598068237 seconds\n"
     ]
    }
   ],
   "source": [
    "# ROWS = 224\n",
    "# COLS = 224\n",
    "# CHANNELS = 43\n",
    "# CLASSES = 2\n",
    "# block_layers = [1,1,1,1]\n",
    "# # Build Network Graph \n",
    "# model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "\n",
    "# # Compile Model \n",
    "# l_rate = 1.e-4\n",
    "# opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "# model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Apply TensorBoard\n",
    "# # # define the logs folder \n",
    "# # log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # # Define TensorBoard Callback\n",
    "# # tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# # Train Model \n",
    "# batch = 32\n",
    "# epochs = 10\n",
    "# start_time = time.time()\n",
    "\n",
    "# history_ResNet18 = model_ResNet18.fit(X_train, y_train_one_hot, \n",
    "#                                       epochs = epochs, batch_size = batch, \n",
    "#                                       validation_data = (X_val, y_val_one_hot))\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e72cf10-6c5c-45dc-b38e-ab491c3be74d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7666656 , 0.23333445],\n",
       "       [0.7796348 , 0.22036527],\n",
       "       [0.79146713, 0.20853293],\n",
       "       [0.79206043, 0.20793962],\n",
       "       [0.75556463, 0.24443538],\n",
       "       [0.78355   , 0.21644998],\n",
       "       [0.7772638 , 0.22273616],\n",
       "       [0.7973107 , 0.20268928],\n",
       "       [0.7658215 , 0.23417851],\n",
       "       [0.77662545, 0.2233745 ],\n",
       "       [0.8071066 , 0.1928934 ],\n",
       "       [0.7514903 , 0.24850976],\n",
       "       [0.79176426, 0.20823574],\n",
       "       [0.8236233 , 0.17637675],\n",
       "       [0.7840638 , 0.21593621],\n",
       "       [0.7984144 , 0.20158562],\n",
       "       [0.78082216, 0.21917789],\n",
       "       [0.7725018 , 0.22749814],\n",
       "       [0.8092341 , 0.19076596]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_ResNet18.predict(X_test)[1:20] # Only Predicts PDL1 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3592bddf-7333-4a15-9342-610b33fa9edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 1.0788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0788371562957764, 0.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_ResNet18.evaluate(X_test[0:5], y_test_one_hot[0:5]) # 0 Accuracy for PDL1 == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a7aa1f-c385-4d6f-9978-f48d236fb541",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Still not improvement: even with balanced dataset, model just predicts one dataset...\n",
    "\n",
    "Until know, we tried to adress the problem as follows: \n",
    "\n",
    "    - Choose biological relevant channels\n",
    "    - Increase number of channels\n",
    "    - Introduce Dropout / Regularization\n",
    "    - Decrease model complexity: ResNet50 --> ResNet18 --> ResNet 10 \n",
    "    - Balanced dataset\n",
    "    --> Still: model only predicts one class in our binary classification task\n",
    "\n",
    "    Next Steps to take: \n",
    "    - Verify label encoding\n",
    "    - Increase model complexity for ResNet\n",
    "    - Dimensionality Reduction \n",
    "    --> If all these steps don't deliver any improvements, then: \n",
    "    - Change Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0da03a-eb17-497c-a7ee-a8a3b266963b",
   "metadata": {},
   "source": [
    "### Verifying Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82d3cb29-6a41-4c3d-9300-21daa0d0ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZTMA224.1_BlockB_SE_123.tiff' 'ZTMA224.1_BlockC_SE_098.tiff'\n",
      " 'ZTMA224.1_BlockB_SE_020.tiff' 'ZTMA20.4_Block1_SE_012.tiff'\n",
      " 'ZTMA224.1_BlockA_SE_003.tiff']\n",
      "[1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Analyze Image Paths\n",
    "\n",
    "print(image_files[0:5]) \n",
    "print(PDL1_score[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06ef1f-2624-4fde-a3d8-1fa5d2ccd57d",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "It seems very likely that the function image_list doesn't follow the order of the metadata.csv data as PDL1_score --> get wrong label encodings..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca081b4-c595-4991-8ddc-71bfe976328b",
   "metadata": {},
   "source": [
    "Adjust import of images in such a way that in imports it in accordance with the PDL1 Score\n",
    "\n",
    "Idea: Import images based on image_file annotation (= sample_id) --> define image_list_and_PDL1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50471227-ac60-4a53-8e33-1e3a5ad91fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/home/jupyter-luvogt/Final_Project_LR/IMC_images' \n",
    "metadata_dir = '/home/jupyter-luvogt/Final_Project_LR/metadata.csv'\n",
    "panel_dir = '/home/jupyter-luvogt/Final_Project_LR/panel.csv' \n",
    "metadata = pd.read_csv(metadata_dir)\n",
    "\n",
    "# Load images CORRECT WITH image_list_and_PDL1\n",
    "images = image_list_and_PDL1(images_dir)[0]\n",
    "images = np.array(images)\n",
    "\n",
    "# Load image files names\n",
    "\n",
    "image_files = image_list_and_PDL1(images_dir)[1] # Define image files for debugging\n",
    "image_files = np.array(image_files)\n",
    "# Load PDL1 to match images --> correct label encoding\n",
    "PDL1_score = image_list_and_PDL1(images_dir)[2] # Define image files for debugging\n",
    "PDL1_score = np.array(PDL1_score)\n",
    "\n",
    "# Transpose and Normalize images\n",
    "images_preproc = [preprocessing(i, transpose = True, normalize = False) for i in images]\n",
    "images_preproc = [preprocessing(i, transpose = False, normalize = True) for i in images_preproc]\n",
    "images_preproc = np.array(images_preproc)\n",
    "\n",
    "# Extract channel information\n",
    "panel_df = pd.read_csv(panel_dir)\n",
    "channel_names = dict(zip(panel_df['clean_target'].to_list(), panel_df['channel'].to_list()))\n",
    "\n",
    "# Filter out Xe131, Xe134 and Ba138 = Noise channels (OPTIONAL) \n",
    "channel_names_new = [x for x in list(channel_names.values()) if x not in [\"Xe131\", \"Xe134\", \"Ba138\"]]\n",
    "images_preproc_drop = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "images_preproc_drop = np.array(images_preproc_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8d4f91-3adc-4326-b0a4-28536360f312",
   "metadata": {},
   "source": [
    "Veryifing correct Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34130869-d268-47e1-9e44-02df477089ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZTMA224.1_BlockB_SE_123.tiff' 'ZTMA224.1_BlockC_SE_098.tiff'\n",
      " 'ZTMA224.1_BlockB_SE_020.tiff' 'ZTMA20.4_Block1_SE_012.tiff'\n",
      " 'ZTMA224.1_BlockA_SE_003.tiff' 'ZTMA20.4_Block2_SE_051.tiff'\n",
      " 'ZTMA20.1_Block3_SE_114.tiff' 'ZTMA224.1_BlockC_SE_107.tiff'\n",
      " 'ZTMA224.2_BlockC_121.tiff' 'ZTMA224.1_BlockA_SE_012.tiff'\n",
      " 'ZTMA224.2_BlockB_073.tiff' 'ZTMA224.1_BlockB_SE_084.tiff'\n",
      " 'ZTMA224.2_BlockB_081.tiff' 'ZTMA20.1_Block2_SE_108.tiff'\n",
      " 'ZTMA224.2_BlockA_082.tiff' 'ZTMA20.1_Block3_SE_056.tiff'\n",
      " 'ZTMA224.2_BlockC_120.tiff' 'ZTMA224.2_BlockC_089.tiff'\n",
      " 'ZTMA224.2_BlockC_037.tiff' 'ZTMA20.1_Block2_SE_055.tiff']\n",
      "[[0], [0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0]]\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(image_files[0:20])\n",
    "\n",
    "print(PDL1_score[0:20].tolist())\n",
    "# Confirming label encoding\n",
    "test = [i.strip(\".tiff\") for i in image_files[0:20]]\n",
    "for i in test:\n",
    "    print(metadata[metadata[\"sample_id\"] == i][\"PDL1_score\"].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6568223-3b1c-4c27-a556-ffa57af18b77",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Labeling seems to be correct now --> Restart with ResNet10 for proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe77d1e-a738-4f7e-8f65-89e120ea2ddd",
   "metadata": {},
   "source": [
    "Training, validation and test split: Downsampling to balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c6f222-17fa-48df-b7eb-36d685b8655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 56\n",
    "X = image_files # Change here if you want 43 channels or 3 channels (images_preproc_drop_3)\n",
    "y = PDL1_score\n",
    "train_size = 0.6; val_size = 0.2; test_size = 0.2\n",
    "# Create a StratifiedShuffleSplit for train/test split\n",
    "sss_train_test = StratifiedShuffleSplit(n_splits=1, test_size=(val_size + test_size), random_state=random_seed)\n",
    "# First split: Train and remaining (validation + test)\n",
    "for train_index, remaining_index in sss_train_test.split(X, y):\n",
    "    X_train, X_remaining = X[train_index], X[remaining_index]\n",
    "    y_train, y_remaining = y[train_index], y[remaining_index]\n",
    "# Create a StratifiedShuffleSplit for validation/test split on remaining data\n",
    "sss_val_test = StratifiedShuffleSplit(n_splits=1, test_size=test_size / (val_size + test_size), random_state=random_seed)\n",
    "# Second split: Validation and Test\n",
    "for val_index, test_index in sss_val_test.split(X_remaining, y_remaining):\n",
    "    X_val, X_test = X_remaining[val_index], X_remaining[test_index]\n",
    "    y_val, y_test = y_remaining[val_index], y_remaining[test_index]\n",
    "\n",
    "CLASSES = 2\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "y_val_one_hot = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0675b13-01fe-4937-a274-b2f160ec9891",
   "metadata": {},
   "source": [
    "Test whether Label encoding correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17606f01-7591-4291-937d-4639e87f1542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ZTMA20.1_Block2_SE_121.tiff' 'ZTMA20.4_Block1_SE_075.tiff'\n",
      " 'ZTMA224.2_BlockB_077.tiff' 'ZTMA224.2_BlockC_128.tiff'\n",
      " 'ZTMA224.1_BlockA_SE_028.tiff' 'ZTMA20.1_Block1_SE_085.tiff'\n",
      " 'ZTMA224.2_BlockC_043.tiff' 'ZTMA20.4_Block1_SE_121.tiff'\n",
      " 'ZTMA224.2_BlockC_120.tiff' 'ZTMA224.2_BlockA_014.tiff'\n",
      " 'ZTMA224.1_BlockA_SE_031.tiff' 'ZTMA224.2_BlockA_032.tiff'\n",
      " 'ZTMA224.1_BlockC_SE_043.tiff' 'ZTMA20.4_Block1_SE_092.tiff'\n",
      " 'ZTMA20.4_Block2_SE_038.tiff' 'ZTMA224.1_BlockB_SE_064.tiff'\n",
      " 'ZTMA224.1_BlockC_SE_041.tiff' 'ZTMA20.1_Block1_SE_026.tiff'\n",
      " 'ZTMA20.4_Block3_SE_074.tiff' 'ZTMA20.1_Block2_SE_070.tiff']\n",
      "[[0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [0.0, 1.0]]\n",
      "1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 1 "
     ]
    }
   ],
   "source": [
    "print(X_val[0:20])\n",
    "print(y_val_one_hot[0:20].tolist())\n",
    "# Confirming label encoding\n",
    "test = [i.strip(\".tiff\") for i in X_val[0:20]]\n",
    "for i in test:\n",
    "    print(metadata[metadata[\"sample_id\"] == i][\"PDL1_score\"].tolist()[0], end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f86597-5105-479d-9428-d62fc1061c86",
   "metadata": {},
   "source": [
    "Retranslate image file names to images themselves\n",
    "\n",
    "Reason: to make sure that Label Encoding stays intact!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c75806-7718-44ad-9664-01a876377c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_array = np.zeros((len(X_train), 224, 224, 43), dtype=np.float32)\n",
    "X_test_array = np.zeros((len(X_test), 224, 224, 43), dtype=np.float32)\n",
    "X_val_array = np.zeros((len(X_val), 224, 224, 43), dtype=np.float32)\n",
    "\n",
    "# CHANGE HERE\n",
    "# X_train_array = np.zeros((len(X_train), 224, 224, 3), dtype=np.float32)\n",
    "# X_test_array = np.zeros((len(X_test), 224, 224, 3), dtype=np.float32)\n",
    "# X_val_array = np.zeros((len(X_val), 224, 224, 3), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7ca24d-d7e2-449b-a00d-385c8868dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names_new = [x for x in list(channel_names.values()) if x not in [\"Xe131\", \"Xe134\", \"Ba138\"]]\n",
    "# channel_names_new = [\"Gd160\", \"Eu153\", \"Gd155\"] # CHANGE HERE \n",
    "for i, x in enumerate(X_train): \n",
    "    image = load_image(os.path.join(images_dir, x))\n",
    "    image = preprocessing(image, transpose = True, normalize = False)\n",
    "    image = preprocessing(image, transpose = False, normalize = True)\n",
    "    image = IMCPreprocessor.drop_channels(image, channel_names_new, list(channel_names.values()))[0]\n",
    "    X_train_array[i] = image\n",
    "\n",
    "for i, x in enumerate(X_test): \n",
    "    image = load_image(os.path.join(images_dir, x))\n",
    "    image = preprocessing(image, transpose = True, normalize = False)\n",
    "    image = preprocessing(image, transpose = False, normalize = True)\n",
    "    image = IMCPreprocessor.drop_channels(image, channel_names_new, list(channel_names.values()))[0]\n",
    "    X_test_array[i] = image\n",
    "\n",
    "for i, x in enumerate(X_val): \n",
    "    image = load_image(os.path.join(images_dir, x))\n",
    "    image = preprocessing(image, transpose = True, normalize = False)\n",
    "    image = preprocessing(image, transpose = False, normalize = True)\n",
    "    image = IMCPreprocessor.drop_channels(image, channel_names_new, list(channel_names.values()))[0]\n",
    "    X_val_array[i] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66b1163a-0597-42a7-93c0-506acbc62c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590, 224, 224, 43)\n",
      "(197, 224, 224, 43)\n",
      "(197, 224, 224, 43)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_array.shape)\n",
    "print(X_test_array.shape)\n",
    "print(X_val_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6895bc51-ec44-4a63-8f38-4dcf58152667",
   "metadata": {},
   "source": [
    "#### Build ResNet10: Correct Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "def05ce5-9e3a-43f1-81a9-1cf7d117ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 637ms/step - accuracy: 0.5725 - loss: 0.9742 - val_accuracy: 0.6396 - val_loss: 0.6693\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - accuracy: 0.7946 - loss: 0.4411 - val_accuracy: 0.6396 - val_loss: 0.6554\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.9198 - loss: 0.2480 - val_accuracy: 0.6396 - val_loss: 0.6526\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.9988 - loss: 0.1251 - val_accuracy: 0.6396 - val_loss: 0.6580\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0516 - val_accuracy: 0.6396 - val_loss: 0.6644\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.6396 - val_loss: 0.6714\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.6396 - val_loss: 0.7431\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.6396 - val_loss: 0.7246\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.6396 - val_loss: 0.8463\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.6396 - val_loss: 0.8664\n",
      "\n",
      "Elapsed time: 61.812899351119995 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224; COLS = 224; CHANNELS = 43; CLASSES = 2 # CHANGE HERE\n",
    "block_layers = [1,1,1,1]\n",
    "# Build Network Graph \n",
    "model_ResNet10 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "model_ResNet10.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train Model \n",
    "batch = 32; epochs = 10\n",
    "start_time = time.time()\n",
    "history_ResNet10 = model_ResNet10.fit(X_train_array, y_train_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch,\n",
    "                                     validation_data = (X_val_array, y_val_one_hot))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a335e8f-efcf-4e0a-a13b-b7b5ea5d2c67",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Even with correct Label Encoding, model still only predicts one class\n",
    "\n",
    "    - Try with balanced dataset again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b17e1-def2-4e9d-9a33-b2ecbb7b7fb8",
   "metadata": {},
   "source": [
    "Balanced Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ec0081-a339-4a78-bd3b-f90cf0dc09dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter-luvogt/.local/lib/python3.12/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# X_train: Define Undersampling balancing method\n",
    "balancer = RandomUnderSampler(random_state = 42) # Undersampling majority class\n",
    "X_train_array_flat = X_train_array.reshape(X_train_array.shape[0], -1) # Reshape images for balancer\n",
    "X_train_array_resampled, y_train_resampled = balancer.fit_resample(X_train_array_flat, y_train) # resample (Undersampling)\n",
    "X_train_array_resampled = X_train_array_resampled.reshape(-1, *X_train_array.shape[1:]) # Reshape the image\n",
    "\n",
    "# X_val: Define Undersampling balancing method\n",
    "balancer = RandomUnderSampler(random_state = 42) # Undersampling majority class\n",
    "X_val_array_flat = X_val_array.reshape(X_val_array.shape[0], -1) # Reshape images for balancer\n",
    "X_val_array_resampled, y_val_resampled = balancer.fit_resample(X_val_array_flat, y_val) # resample (Undersampling)\n",
    "X_val_array_resampled = X_val_array_resampled.reshape(-1, *X_val_array.shape[1:]) # Reshape the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "909c4ba8-3782-4cfc-9e04-ca2243348a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 224, 224, 43)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_array_resampled.shape)\n",
    "y_train_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a827e7-d178-4ca9-a064-2fa20c06f276",
   "metadata": {},
   "source": [
    "Reshuffle labels and X_training_array_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a279ed4-3629-43c8-a7fe-5ab0de8e6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# X_train: Shuffle the data and labels together\n",
    "X_train_array_resampled, y_train_resampled = shuffle(X_train_array_resampled, y_train_resampled, random_state=42)\n",
    "y_train_resampled_one_hot = to_categorical(y_train_resampled)\n",
    "\n",
    "# X_val: Shuffle the data and labels together\n",
    "X_val_array_resampled, y_val_resampled = shuffle(X_val_array_resampled, y_val_resampled, random_state=42)\n",
    "y_val_resampled_one_hot = to_categorical(y_val_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80d648-f9c2-4c3e-ba5d-90dce0eb355a",
   "metadata": {},
   "source": [
    "#### Build ResNet10: Correct Label Encoding + downsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7b9b4ab-252e-49ff-8ed3-f93ccd0ed91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5665 - loss: 0.9178 - val_accuracy: 0.5000 - val_loss: 0.6927\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 326ms/step - accuracy: 0.8440 - loss: 0.4000 - val_accuracy: 0.5000 - val_loss: 0.6974\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 325ms/step - accuracy: 0.9202 - loss: 0.2447 - val_accuracy: 0.5000 - val_loss: 0.7015\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 326ms/step - accuracy: 0.9726 - loss: 0.1184 - val_accuracy: 0.5000 - val_loss: 0.7007\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 326ms/step - accuracy: 0.9958 - loss: 0.1013 - val_accuracy: 0.5000 - val_loss: 0.7244\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 0.0471 - val_accuracy: 0.5000 - val_loss: 0.7107\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 326ms/step - accuracy: 1.0000 - loss: 0.0270 - val_accuracy: 0.5000 - val_loss: 0.7208\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.5000 - val_loss: 0.7527\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 325ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.5000 - val_loss: 0.7419\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.5000 - val_loss: 0.7333\n",
      "\n",
      "Elapsed time: 48.44438672065735 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224; COLS = 224; CHANNELS = 43; CLASSES = 2 # CHANGE HERE\n",
    "block_layers = [1,1,1,1]\n",
    "# Build Network Graph \n",
    "model_ResNet10 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "model_ResNet10.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train Model \n",
    "batch = 64; epochs = 10\n",
    "start_time = time.time()\n",
    "history_ResNet10 = model_ResNet10.fit(X_train_array_resampled, y_train_resampled_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch,\n",
    "                                     validation_data = (X_val_array_resampled, y_val_resampled_one_hot))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61de9de4-5b2a-4886-8a2b-94276ee14984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7569167 , 0.24308333],\n",
       "       [0.75380856, 0.24619144],\n",
       "       [0.7734363 , 0.2265637 ],\n",
       "       [0.73854095, 0.26145902],\n",
       "       [0.7827304 , 0.21726963],\n",
       "       [0.76103044, 0.23896958],\n",
       "       [0.7624994 , 0.23750056],\n",
       "       [0.75138694, 0.24861306],\n",
       "       [0.7599778 , 0.24002218],\n",
       "       [0.7732955 , 0.2267044 ],\n",
       "       [0.76910627, 0.2308937 ],\n",
       "       [0.7638732 , 0.2361268 ],\n",
       "       [0.7767476 , 0.22325242],\n",
       "       [0.7504792 , 0.24952078],\n",
       "       [0.74204266, 0.25795737],\n",
       "       [0.7424291 , 0.25757092],\n",
       "       [0.782885  , 0.21711498],\n",
       "       [0.72948205, 0.27051795],\n",
       "       [0.75849605, 0.24150394],\n",
       "       [0.7581919 , 0.24180807]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ResNet10.predict(X_val_array_resampled)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb6f29-51f5-48e9-9bae-6b8f25aec940",
   "metadata": {},
   "source": [
    "### ResNet101: Try more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "405df34f-e902-475a-822e-5b2d3f4e9b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 13:09:38.584236: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3676495872 exceeds 10% of free system memory.\n",
      "2024-12-15 13:09:40.307908: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3676495872 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734268211.511209  667327 service.cc:146] XLA service 0x7f1998002720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734268211.511251  667327 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-15 13:10:12.663400: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-15 13:10:16.276678: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "I0000 00:00:1734268244.120297  667327 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 6s/step - accuracy: 0.5278 - loss: 3.4380 - val_accuracy: 0.5000 - val_loss: 0.7022\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750ms/step - accuracy: 0.5908 - loss: 1.3838 - val_accuracy: 0.5000 - val_loss: 0.7010\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 754ms/step - accuracy: 0.7173 - loss: 0.7623 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 756ms/step - accuracy: 0.8415 - loss: 0.4475 - val_accuracy: 0.5000 - val_loss: 0.7086\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 758ms/step - accuracy: 0.9358 - loss: 0.3303 - val_accuracy: 0.5000 - val_loss: 0.7278\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 760ms/step - accuracy: 0.9183 - loss: 0.2453 - val_accuracy: 0.5000 - val_loss: 0.7110\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 761ms/step - accuracy: 0.9913 - loss: 0.1156 - val_accuracy: 0.5000 - val_loss: 0.7169\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 758ms/step - accuracy: 1.0000 - loss: 0.0478 - val_accuracy: 0.5000 - val_loss: 0.6993\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 763ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.5000 - val_loss: 0.6965\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 761ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.5000 - val_loss: 0.7007\n",
      "\n",
      "Elapsed time: 155.97168064117432 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224; COLS = 224; CHANNELS = 43; CLASSES = 2\n",
    "block_layers = [3,4,23,3]\n",
    "# Build Network Graph \n",
    "model_ResNet101 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "model_ResNet101.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train Model \n",
    "batch = 64; epochs = 10\n",
    "start_time = time.time()\n",
    "history_ResNet101 = model_ResNet101.fit(X_train_array_resampled, y_train_resampled_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch,\n",
    "                                     validation_data = (X_val_array_resampled, y_val_resampled_one_hot))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "453437da-4946-487c-a6f4-e5c033c17135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.63307756, 0.3669224 ],\n",
       "       [0.59208673, 0.4079133 ],\n",
       "       [0.5898937 , 0.41010627],\n",
       "       [0.5683737 , 0.43162635],\n",
       "       [0.6350663 , 0.3649337 ],\n",
       "       [0.6089314 , 0.3910686 ],\n",
       "       [0.6027144 , 0.3972856 ],\n",
       "       [0.6252898 , 0.37471014],\n",
       "       [0.6122896 , 0.38771036],\n",
       "       [0.62071234, 0.37928772],\n",
       "       [0.60527813, 0.39472184],\n",
       "       [0.60391414, 0.3960858 ],\n",
       "       [0.62466466, 0.37533534],\n",
       "       [0.5985049 , 0.40149507],\n",
       "       [0.6146456 , 0.38535446],\n",
       "       [0.5900499 , 0.40995008],\n",
       "       [0.630843  , 0.36915702],\n",
       "       [0.5908219 , 0.40917808],\n",
       "       [0.59003   , 0.40997002],\n",
       "       [0.5835712 , 0.41642877]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ResNet101.predict(X_val_array_resampled)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42e41365-78bc-4652-b25c-09929d525338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.5237 - loss: 0.7004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7043793201446533, 0.5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ResNet101.evaluate(X_train_array_resampled, y_train_resampled_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96099465-512e-481b-821a-5b28d5d17258",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Even with Correct Label Encoding, and different complexities of ResNet, and balanced datasets (downsampling), and different number of channels (3 vs. 43), the model only predicts one class.\n",
    "\n",
    "Note: When using 43 Channels, the probabilities get closer to 0.5, while when using 3 channels, the probabilities are close to 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253d6e0-73b6-41e3-963a-bea88c4f882b",
   "metadata": {},
   "source": [
    "### Increase Model complexity: ResNet 101"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BME342 Env",
   "language": "python",
   "name": "bme342_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
