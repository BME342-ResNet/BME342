{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d00de6-d8b1-49e0-a822-0772236e8def",
   "metadata": {},
   "source": [
    "### ResNet: Tensorflow Train\n",
    "\n",
    "Due to difficulty overcoming overfitting with the previous approaches, and probably the data preprocessing being a potential source of error, \n",
    "\n",
    "the whole data importing and preprocessing was revised by first constructing a model with PyTorch and then translating it into tensorflow/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e295a38-9f17-47a3-a3de-716688e75b7e",
   "metadata": {},
   "source": [
    "### Initialize Notebook & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931d2ee7-86e4-47e3-a404-20aee57a5b83",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 20:52:35.179803: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-17 20:52:35.194355: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-17 20:52:35.198878: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-17 20:52:35.210010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled. Checking for available GPUs...\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "\n",
      "Verifying TensorFlow and PyTorch CUDA setup...\n",
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: True\n",
      "Num GPUs Available: 1\n",
      "\n",
      "Keras version: 3.6.0\n",
      "\n",
      "End checks and initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734468757.147531  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734468757.190649  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734468757.194269  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734468757.199414  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734468757.202834  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734468757.206068  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734468757.397518  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734468757.399576  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734468757.401442  735806 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-17 20:52:37.403263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13312 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import helper as hp \n",
    "hp.initialize_notebook() # initialize with GPU enabled  \n",
    "# hp.initialize_notebook(False) # to disable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e505a7a3-0dcf-4cfe-8b7a-9db2438479f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras\n",
    "# Import DL libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout # General Layers\n",
    "from keras.layers import RandomRotation, RandomFlip\n",
    "from keras import layers, models, Model, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "# Suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Import image libraries\n",
    "from skimage import transform\n",
    "import tifffile as tiff\n",
    "from tifffile import imread\n",
    "\n",
    "# Appends current working dir\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "\n",
    "# Import custom preprocessing class\n",
    "from imc_preprocessing import IMCPreprocessor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d006ba8a-9e06-4123-91a3-9211efd42ff3",
   "metadata": {},
   "source": [
    "## IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c1bad0-b617-4dd6-a217-5b3386e1672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/home/jupyter-luvogt/Final_Project_LR/IMC_images' \n",
    "metadata_dir = '/home/jupyter-luvogt/Final_Project_LR/metadata.csv'\n",
    "# --- Load CSV and filter dataset ---\n",
    "csv_file = metadata_dir\n",
    "image_folder = images_dir\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Filter rows with NA in PDL1_score and convert to binary\n",
    "df = df.dropna(subset=[\"PDL1_score\"])\n",
    "df[\"PDL1_score\"] = df[\"PDL1_score\"].astype(int)\n",
    "\n",
    "# --- Train-Test-Validation Split ---\n",
    "train_df, val_and_test_df = train_test_split(df, test_size=0.4, random_state=42, stratify=df[\"PDL1_score\"])\n",
    "test_df, val_df = train_test_split(val_and_test_df, test_size=0.5, random_state=42, stratify=val_and_test_df[\"PDL1_score\"])\n",
    "\n",
    "# --- Load Images and Compute Mean and Standard Deviation ---\n",
    "\n",
    "# Function to load a single image\n",
    "def load_image(image_path):\n",
    "    image = imread(image_path)  # Load all 46 channels\n",
    "    return image.astype(np.float32)\n",
    "\n",
    "# Initialize variables to accumulate sum and sum of squares\n",
    "nr_images = 0\n",
    "sum_images = np.zeros((46, 224, 224))\n",
    "sum_squared_images = np.zeros((46, 224, 224))\n",
    "\n",
    "# Accumulate the sum and sum of squares for the training dataset\n",
    "for _, row in train_df.iterrows():\n",
    "    image_path = os.path.join(image_folder, f\"{row['sample_id']}.tiff\")\n",
    "    image = load_image(image_path)\n",
    "    nr_images += 1\n",
    "    sum_images += image\n",
    "    sum_squared_images += image ** 2\n",
    "\n",
    "# Compute mean and standard deviation\n",
    "mean = sum_images / nr_images\n",
    "std = np.sqrt(sum_squared_images / nr_images - mean ** 2)\n",
    "\n",
    "# --- Dataset Loading Function ---\n",
    "\n",
    "def load_dataset(dataframe, image_folder, normalize = True): # augment = False\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in dataframe.iterrows():\n",
    "        image_path = os.path.join(image_folder, f\"{row['sample_id']}.tiff\")\n",
    "        image = load_image(image_path)\n",
    "\n",
    "        if normalize:\n",
    "            image = (image - mean) / std # Z-Score\n",
    "\n",
    "        # Convert to channels-last format (224, 224, 46)\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "        # # Apply data augmentation if specified\n",
    "        # if augment:\n",
    "        #     # Random horizontal flip\n",
    "        #     if np.random.rand() > 0.5:\n",
    "        #         image = np.flip(image, axis=2)\n",
    "        #     # Random vertical flip\n",
    "        #     if np.random.rand() > 0.5:\n",
    "        #         image = np.flip(image, axis=1)\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(row[\"PDL1_score\"])\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e7985-680d-47cc-93f6-4265dc6a7742",
   "metadata": {},
   "source": [
    "### Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d08b095-bb6e-4a8c-b704-500debe1c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (590, 224, 224, 46), y_train shape: (590, 2)\n",
      "X_val shape: (197, 224, 224, 46), y_val shape: (197, 2)\n",
      "X_test shape: (197, 224, 224, 46), y_test shape: (197, 2)\n"
     ]
    }
   ],
   "source": [
    "# Training dataset without augmentation\n",
    "X_train, y_train = load_dataset(train_df, image_folder, normalize = True)\n",
    "# # Training dataset with data augmentation\n",
    "# X_train_aug, y_train_aug = load_dataset(train_df, image_folder, augment=True)\n",
    "# Validation dataset\n",
    "X_val, y_val = load_dataset(val_df, image_folder, normalize = True)\n",
    "# Test dataset\n",
    "X_test, y_test = load_dataset(test_df, image_folder, normalize = True)\n",
    "\n",
    "# One Hot Encoding\n",
    "y_train= to_categorical(y_train)\n",
    "y_val= to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9026830-64d9-4804-8410-bd530ba4b63e",
   "metadata": {},
   "source": [
    "Verifying Normalization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430ea106-47bb-40bd-b507-4f7d5cce29a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.562353140428533e-17\n",
      "0.9999999999582869\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(X_train)) # Mean = 0\n",
    "print(np.std(X_train)) # Standard deviation = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e253fd7-0484-4dcd-b62e-f45f0653df12",
   "metadata": {},
   "source": [
    "#### Define building blocks of ResNet network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52950d6-decb-4009-9788-21fc4f22d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "def identity_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3]):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34f67d-6993-42bf-8489-67ff1b4bf018",
   "metadata": {},
   "source": [
    "### Train ResNet18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f12233-96d4-4f7b-8b5a-7761e919cbb6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 21:56:04.174899: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-16 21:56:06.763387: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734386177.548504  707518 service.cc:146] XLA service 0x7f3a84047f90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734386177.548548  707518 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-16 21:56:17.779099: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-16 21:56:18.721282: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "2024-12-16 21:56:21.114400: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1734386195.896974  707518 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.5936 - loss: 1.6235 - val_accuracy: 0.5939 - val_loss: 1.4351\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.8380 - loss: 0.5075 - val_accuracy: 0.6396 - val_loss: 1.2642\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 394ms/step - accuracy: 0.9316 - loss: 0.2125 - val_accuracy: 0.5076 - val_loss: 1.3793\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 390ms/step - accuracy: 0.9400 - loss: 0.1483 - val_accuracy: 0.5228 - val_loss: 1.2674\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 396ms/step - accuracy: 0.9900 - loss: 0.0642 - val_accuracy: 0.6751 - val_loss: 0.9535\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 399ms/step - accuracy: 0.9989 - loss: 0.0313 - val_accuracy: 0.6599 - val_loss: 0.9824\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 400ms/step - accuracy: 0.9951 - loss: 0.0244 - val_accuracy: 0.6802 - val_loss: 1.0263\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 402ms/step - accuracy: 0.9994 - loss: 0.0112 - val_accuracy: 0.6701 - val_loss: 1.0922\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 394ms/step - accuracy: 0.9978 - loss: 0.0127 - val_accuracy: 0.6904 - val_loss: 1.0897\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 400ms/step - accuracy: 0.9978 - loss: 0.0120 - val_accuracy: 0.6853 - val_loss: 1.1916\n",
      "\n",
      "Elapsed time: 94.11959147453308 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [2,2,2,2]\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Apply TensorBoard\n",
    "# # define the logs folder \n",
    "# log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # Define TensorBoard Callback\n",
    "# tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2604874e-48c8-47ac-a2d8-fa42d4d6725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ResNet18.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63325950-9d67-4663-8186-c7ef7564e94c",
   "metadata": {},
   "source": [
    "Finally, we have a Validation Accuracy above the baseline accuracy, giving us a proof of concept and giving us the ability to experiment further with: \n",
    "\n",
    "For now, we have 68.58% test accuracy\n",
    "\n",
    "    - Different ResNet Architecture: ResNet18, ResNet50, and pre-trained ResNets\n",
    "    - Data Augmentation\n",
    "    - Dimensionality Reduction: Autoencoder\n",
    "    - Feature Engineering: Channel Selection --> e.g. only biological relevant channels / feed bottleneck layer of autoencoder into ResNet\n",
    "    - Regularizations: Regularizer and Dropouts\n",
    "    - Callbacks\n",
    "    - Monitor hyperparameters with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de0a6b-9698-4522-86ee-718be817ca9a",
   "metadata": {},
   "source": [
    "## ResNet18: with Tensor Board + 46 Channels + without Regularization + no callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1ed662-89c2-48b4-9e82-8314b92e2e1a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 21:02:24.733828: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-15 21:02:30.556470: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 21:02:44.753749: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.5743 - loss: 1.5904 - val_accuracy: 0.6396 - val_loss: 1.6029\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 574ms/step - accuracy: 0.7853 - loss: 0.5136 - val_accuracy: 0.6447 - val_loss: 0.9970\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 548ms/step - accuracy: 0.8780 - loss: 0.2858 - val_accuracy: 0.4010 - val_loss: 1.5503\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 555ms/step - accuracy: 0.9531 - loss: 0.1533 - val_accuracy: 0.6802 - val_loss: 0.7513\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 561ms/step - accuracy: 0.9848 - loss: 0.0689 - val_accuracy: 0.6701 - val_loss: 0.8414\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 562ms/step - accuracy: 0.9822 - loss: 0.0776 - val_accuracy: 0.6396 - val_loss: 1.0069\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 541ms/step - accuracy: 0.9925 - loss: 0.0457 - val_accuracy: 0.7157 - val_loss: 0.8810\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 573ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.6853 - val_loss: 0.8911\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 597ms/step - accuracy: 0.9986 - loss: 0.0057 - val_accuracy: 0.6954 - val_loss: 0.9259\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 575ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.6904 - val_loss: 1.0552\n",
      "\n",
      "Elapsed time: 109.94851922988892 seconds\n"
     ]
    }
   ],
   "source": [
    "# from keras.callbacks import TensorBoard \n",
    "# ROWS = 224\n",
    "# COLS = 224\n",
    "# CHANNELS = 46\n",
    "# CLASSES = 2\n",
    "# block_layers = [2,2,2,2] # ResNet18\n",
    "# # Build Network Graph \n",
    "# model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "\n",
    "# # Compile Model \n",
    "# l_rate = 1.e-4\n",
    "# opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "# model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Apply TensorBoard\n",
    "# # define the logs folder \n",
    "# log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_no_regularization_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # Define TensorBoard Callback\n",
    "# tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# # Train Model \n",
    "# batch = 64\n",
    "# epochs = 10\n",
    "# start_time = time.time()\n",
    "\n",
    "# history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "#                                       epochs = epochs, batch_size = batch, \n",
    "#                                       validation_data = (X_val, y_val), callbacks = tb_callback)\n",
    "\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b6fa15-0f72-49c1-a757-d5f621187d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 1.0567\n",
      "Test Accuracy is: 0.65%\n"
     ]
    }
   ],
   "source": [
    "# #### Test accuracy\n",
    "# print(\"Test Accuracy is: {:.2f}%\".format(model_ResNet18.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585dd86-5f33-4eb9-8931-56836dec602c",
   "metadata": {},
   "source": [
    "#### SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4aebb33-b899-490f-bc92-dec3aaa29e95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # Save the model\n",
    "# model_ResNet18.save('./models_ResNet/model_ResNet18_46_no_regularization_trained.keras')\n",
    "# # Save the history of your experiments \n",
    "# with open('./models_ResNet/history_red_LR.pkl', 'wb') as f:\n",
    "#     pickle.dump(history_ResNet18.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ffe47c-ec7a-425a-bc33-fe919f827fa7",
   "metadata": {},
   "source": [
    "## ResNet18: with Tensor Board + 46 Channels + without Regularization + ReduceLR + EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "610e88cc-d3c6-40c2-98d1-f39c1638d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_no_regularization_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet18_46_no_regularization_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f78d2f-35e0-4636-bc5c-1aa0535feb66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [2,2,2,2] # ResNet18\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_no_regularization_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feaef6b7-943e-40fa-ad2c-243ae7c2f09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7067 - loss: 0.9014\n",
      "Test Accuracy is: 0.71%\n"
     ]
    }
   ],
   "source": [
    "# #### Test accuracy\n",
    "# print(\"Test Accuracy is: {:.2f}%\".format(model_ResNet18.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350440f3-3a72-44eb-94bf-83fe1fda4343",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Test accuracy improved a little bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9438e52-ae23-4c99-b25f-4834b8cb93f7",
   "metadata": {},
   "source": [
    "#### SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d773db4-2ff8-428c-a301-e5a1e52ef3b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # Save the model\n",
    "# model_ResNet18.save('./models_ResNet/model_ResNet18_46_no_regularization_callbacks_trained.keras')\n",
    "# # Save the history of your experiments \n",
    "# with open('./models_ResNet/history_ResNet18_46_no_regularization_callbacks_trained.pkl', 'wb') as f:\n",
    "#     pickle.dump(history_ResNet18.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306615f-7fbe-4702-97ac-7cec5f051fb3",
   "metadata": {},
   "source": [
    "## ResNet18: with Tensor Board + 46 Channels + with Dropout + ReduceLR + EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16897799-090b-4b2b-b2d7-edcc7d925976",
   "metadata": {},
   "source": [
    "### Redefine Network with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44db92f7-d88f-4b3b-b39d-37fa28583602",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3], dropout_rate = 0.5):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf3149-99db-4977-a4b7-00dfd8081aa9",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42af721f-0a70-43e3-9aa8-12ddf1562b53",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet18_46_dropout_callbacks_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bdf718-5b20-49d6-81d1-1510ea4f6f85",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4396d29c-0615-45f1-acb5-709b284c89c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 22:38:08.175871: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-16 22:38:10.772640: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.5879 - loss: 1.2561 - val_accuracy: 0.3959 - val_loss: 0.9601 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 726ms/step - accuracy: 0.6510 - loss: 0.7719 - val_accuracy: 0.6142 - val_loss: 0.7999 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 764ms/step - accuracy: 0.6864 - loss: 0.6412 - val_accuracy: 0.6091 - val_loss: 0.7165 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 732ms/step - accuracy: 0.7789 - loss: 0.4920 - val_accuracy: 0.7411 - val_loss: 0.5554 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 743ms/step - accuracy: 0.8212 - loss: 0.4330 - val_accuracy: 0.7766 - val_loss: 0.5228 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 628ms/step - accuracy: 0.8155 - loss: 0.4223 - val_accuracy: 0.7665 - val_loss: 0.5546 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 639ms/step - accuracy: 0.8750 - loss: 0.3575 - val_accuracy: 0.7817 - val_loss: 0.5819 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 765ms/step - accuracy: 0.8909 - loss: 0.2955 - val_accuracy: 0.8122 - val_loss: 0.4804 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 610ms/step - accuracy: 0.8440 - loss: 0.3861 - val_accuracy: 0.7259 - val_loss: 0.9289 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 616ms/step - accuracy: 0.8693 - loss: 0.3474 - val_accuracy: 0.8020 - val_loss: 0.6154 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8876 - loss: 0.3160\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 631ms/step - accuracy: 0.8868 - loss: 0.3163 - val_accuracy: 0.8274 - val_loss: 0.5310 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 775ms/step - accuracy: 0.9037 - loss: 0.2744 - val_accuracy: 0.8325 - val_loss: 0.4681 - learning_rate: 5.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 727ms/step - accuracy: 0.9121 - loss: 0.2369 - val_accuracy: 0.8274 - val_loss: 0.4276 - learning_rate: 5.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 616ms/step - accuracy: 0.9130 - loss: 0.2536 - val_accuracy: 0.8020 - val_loss: 0.4454 - learning_rate: 5.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 759ms/step - accuracy: 0.9139 - loss: 0.2444 - val_accuracy: 0.8376 - val_loss: 0.4172 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 618ms/step - accuracy: 0.8826 - loss: 0.2738 - val_accuracy: 0.7817 - val_loss: 0.5065 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 605ms/step - accuracy: 0.9086 - loss: 0.2414 - val_accuracy: 0.8376 - val_loss: 0.4386 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9266 - loss: 0.2375\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 606ms/step - accuracy: 0.9245 - loss: 0.2420 - val_accuracy: 0.8325 - val_loss: 0.4387 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 598ms/step - accuracy: 0.9053 - loss: 0.2390 - val_accuracy: 0.8376 - val_loss: 0.4332 - learning_rate: 2.5000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 758ms/step - accuracy: 0.8903 - loss: 0.2644 - val_accuracy: 0.8376 - val_loss: 0.4135 - learning_rate: 2.5000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 614ms/step - accuracy: 0.9107 - loss: 0.2316 - val_accuracy: 0.8325 - val_loss: 0.4461 - learning_rate: 2.5000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 610ms/step - accuracy: 0.8993 - loss: 0.2409 - val_accuracy: 0.8274 - val_loss: 0.4144 - learning_rate: 2.5000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9055 - loss: 0.2172\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 606ms/step - accuracy: 0.9053 - loss: 0.2188 - val_accuracy: 0.8223 - val_loss: 0.5095 - learning_rate: 2.5000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 583ms/step - accuracy: 0.9168 - loss: 0.2094 - val_accuracy: 0.8223 - val_loss: 0.4743 - learning_rate: 1.2500e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 586ms/step - accuracy: 0.9299 - loss: 0.1879 - val_accuracy: 0.8426 - val_loss: 0.4289 - learning_rate: 1.2500e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9273 - loss: 0.2050\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 604ms/step - accuracy: 0.9270 - loss: 0.2047 - val_accuracy: 0.8274 - val_loss: 0.4160 - learning_rate: 1.2500e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 601ms/step - accuracy: 0.9214 - loss: 0.2053 - val_accuracy: 0.8274 - val_loss: 0.4250 - learning_rate: 6.2500e-06\n",
      "Epoch 28/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 599ms/step - accuracy: 0.8962 - loss: 0.2135 - val_accuracy: 0.8325 - val_loss: 0.4288 - learning_rate: 6.2500e-06\n",
      "\n",
      "Elapsed time: 247.44629788398743 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [2,2,2,2] # ResNet18\n",
    "dropout_rate = 0.5\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9a1cd-6a5d-4ee3-a7fd-5748969ad2c7",
   "metadata": {},
   "source": [
    "### Testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf597f0-95b9-4705-b51b-d12d96790105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 11:13:12.474325: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 13.00GiB (13958643712 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.474477: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 11.70GiB (12562779136 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.474584: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 10.53GiB (11306501120 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.474692: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 9.48GiB (10175850496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.474794: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 8.53GiB (9158264832 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.474918: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 7.68GiB (8242438144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475019: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.91GiB (7418193920 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475116: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 6.22GiB (6676374528 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475212: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 5.60GiB (6008736768 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475307: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 5.04GiB (5407862784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475401: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 4.53GiB (4867076608 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475505: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 4.08GiB (4380368896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475602: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 3.67GiB (3942331904 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475695: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 3.30GiB (3548098560 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475786: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 2.97GiB (3193288704 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475876: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 2.68GiB (2873959680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.475966: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 2.41GiB (2586563584 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.476055: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 2.17GiB (2327907072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.476146: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.95GiB (2095116288 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.476234: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.76GiB (1885604608 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.476321: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.58GiB (1697044224 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-12-17 11:13:12.476409: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 1.42GiB (1527339776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "# To load the model from file uncomment and run the following \n",
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_callbacks_trained.keras')\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea75d20-6469-4107-9c80-fad079aaf4c5",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Test accuracy imporoved from 0.71% (without dropout) to 0.82%! \n",
    "\n",
    "Conclusion: Dropout helped a lot\n",
    "\n",
    "    - Try Dropout_rate of 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574947b8-cb06-4e44-9652-ad2595314509",
   "metadata": {},
   "source": [
    "### Dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb75752-005d-409b-af03-93121d0ae166",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fef8f42-12b1-4f52-8146-5dd7f47a3d57",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_0.2_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet18_46_dropout_0.2_callbacks_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e856a-52f4-4fef-8f4e-e36fc3b0e24e",
   "metadata": {},
   "source": [
    "### Train Model: Drop out = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e7462d1-ff29-4b6e-9ddd-06d00cfafd5a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 16:52:06.962581: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-16 16:52:09.562428: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734367941.323721  689163 service.cc:146] XLA service 0x7fa1b00424f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734367941.323763  689163 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-16 16:52:21.599593: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-16 16:52:22.615901: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "2024-12-16 16:52:26.275057: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1734367966.576675  689163 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 0.6443 - loss: 1.2264 - val_accuracy: 0.3909 - val_loss: 1.2085 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 714ms/step - accuracy: 0.5982 - loss: 0.8102 - val_accuracy: 0.4010 - val_loss: 1.1494 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 751ms/step - accuracy: 0.6748 - loss: 0.6892 - val_accuracy: 0.5990 - val_loss: 0.8231 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 611ms/step - accuracy: 0.6561 - loss: 0.6718 - val_accuracy: 0.4162 - val_loss: 0.9373 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 753ms/step - accuracy: 0.7232 - loss: 0.5525 - val_accuracy: 0.6091 - val_loss: 0.7570 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 799ms/step - accuracy: 0.7689 - loss: 0.4972 - val_accuracy: 0.6396 - val_loss: 0.6944 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 620ms/step - accuracy: 0.8461 - loss: 0.4028 - val_accuracy: 0.6447 - val_loss: 0.8401 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 644ms/step - accuracy: 0.8553 - loss: 0.3183 - val_accuracy: 0.7005 - val_loss: 0.7812 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.8518 - loss: 0.3532\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 643ms/step - accuracy: 0.8529 - loss: 0.3527 - val_accuracy: 0.5939 - val_loss: 1.4538 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 621ms/step - accuracy: 0.8728 - loss: 0.3045 - val_accuracy: 0.7411 - val_loss: 0.7612 - learning_rate: 5.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 755ms/step - accuracy: 0.8826 - loss: 0.2770 - val_accuracy: 0.7462 - val_loss: 0.6832 - learning_rate: 5.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 754ms/step - accuracy: 0.8927 - loss: 0.2815 - val_accuracy: 0.7614 - val_loss: 0.6579 - learning_rate: 5.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 776ms/step - accuracy: 0.9095 - loss: 0.2401 - val_accuracy: 0.7868 - val_loss: 0.5354 - learning_rate: 5.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 635ms/step - accuracy: 0.9186 - loss: 0.2247 - val_accuracy: 0.7665 - val_loss: 0.5628 - learning_rate: 5.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 636ms/step - accuracy: 0.9049 - loss: 0.2415 - val_accuracy: 0.7919 - val_loss: 0.5378 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 808ms/step - accuracy: 0.9070 - loss: 0.2332 - val_accuracy: 0.7817 - val_loss: 0.4873 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 643ms/step - accuracy: 0.8692 - loss: 0.3154 - val_accuracy: 0.8020 - val_loss: 0.5144 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 631ms/step - accuracy: 0.9111 - loss: 0.2294 - val_accuracy: 0.7970 - val_loss: 0.4896 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 764ms/step - accuracy: 0.9007 - loss: 0.2349 - val_accuracy: 0.8071 - val_loss: 0.4790 - learning_rate: 5.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 618ms/step - accuracy: 0.9102 - loss: 0.2342 - val_accuracy: 0.8071 - val_loss: 0.5157 - learning_rate: 5.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 634ms/step - accuracy: 0.8924 - loss: 0.2503 - val_accuracy: 0.8274 - val_loss: 0.5695 - learning_rate: 5.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9195 - loss: 0.1995\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 640ms/step - accuracy: 0.9189 - loss: 0.2008 - val_accuracy: 0.8071 - val_loss: 0.5659 - learning_rate: 5.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 629ms/step - accuracy: 0.9179 - loss: 0.2156 - val_accuracy: 0.8274 - val_loss: 0.5480 - learning_rate: 2.5000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 616ms/step - accuracy: 0.9316 - loss: 0.1847 - val_accuracy: 0.7970 - val_loss: 0.5330 - learning_rate: 2.5000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.9382 - loss: 0.1610\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 594ms/step - accuracy: 0.9365 - loss: 0.1647 - val_accuracy: 0.8020 - val_loss: 0.5476 - learning_rate: 2.5000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 615ms/step - accuracy: 0.9039 - loss: 0.2323 - val_accuracy: 0.8071 - val_loss: 0.5464 - learning_rate: 1.2500e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 627ms/step - accuracy: 0.9406 - loss: 0.1900 - val_accuracy: 0.8122 - val_loss: 0.5303 - learning_rate: 1.2500e-05\n",
      "\n",
      "Elapsed time: 290.661292552948 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [2,2,2,2] # ResNet18\n",
    "dropout_rate = 0.2\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_0.2_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b591dd4-b317-41d3-afd2-5d9ad2909cda",
   "metadata": {},
   "source": [
    "### Testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a73d2d4-d0ba-4a0b-a296-fb53f05a9705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - accuracy: 0.7960 - loss: 0.6576\n",
      "Test Accuracy is: 0.80%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_0.2_callbacks_trained.keras') # Loading best model\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931b30a1-e006-440b-87e5-13a8d089aefd",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "With Dropout = 0.2, the test accuracy decreased from 81% (drop rate = 0.5) to 80% (drop rate = 0.2)\n",
    "\n",
    "    - stick with dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c91ff-fba4-41f8-92ba-bd07b4356aa6",
   "metadata": {},
   "source": [
    "## ResNet18: with Tensor Board + 46 Channels + with Dropout + L2 Regularization + ReduceLR + EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c21a7-f4c4-4252-af25-3941a494e1c0",
   "metadata": {},
   "source": [
    "### Redefine Network with Dropout + Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a662530-1ab8-4b09-a117-6f95ca7c6dce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "def identity_block(x, filter, dropout_rate = 0.5, l2_lambda=0.01):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter, dropout_rate=0.5, l2_lambda=0.01):\n",
    "    # Copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "\n",
    "    # Layer 1\n",
    "    x = Conv2D(filter, (3, 3), padding='same', strides=(2, 2), kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Layer 2\n",
    "    x = Conv2D(filter, (3, 3), padding='same', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    # Processing Residue with Conv(1,1)\n",
    "    x_skip = Conv2D(filter, (1, 1), strides=(2, 2), kernel_regularizer=l2(l2_lambda))(x_skip)\n",
    "\n",
    "    # Add Residue\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3], dropout_rate = 0.5, l2_lambda=0.01):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu', kernel_regularizer=l2(l2_lambda))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ba444-5a2d-4622-b5cc-46f61e51b353",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "Monitor val_accuracy because of regularization (val_loss keeps decreasing with epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd976f6-6c38-486c-a97a-38eda5550636",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_L2_regularizer_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet18_46_dropout_L2_regularizer_callbacks_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_accuracy\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d02cc3-79a4-4ad7-9641-5ded7596931e",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "936c92a4-339a-49fb-9f27-8096aa9d3f4e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.5607 - loss: 52.9221 - val_accuracy: 0.3807 - val_loss: 51.7925 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 777ms/step - accuracy: 0.6667 - loss: 51.3067 - val_accuracy: 0.4467 - val_loss: 50.6384 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 730ms/step - accuracy: 0.6728 - loss: 50.1471 - val_accuracy: 0.4721 - val_loss: 49.5554 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 758ms/step - accuracy: 0.6620 - loss: 49.0660 - val_accuracy: 0.6193 - val_loss: 48.3070 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 759ms/step - accuracy: 0.7107 - loss: 47.8851 - val_accuracy: 0.6802 - val_loss: 47.1205 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 751ms/step - accuracy: 0.7744 - loss: 46.6286 - val_accuracy: 0.7462 - val_loss: 45.8442 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 631ms/step - accuracy: 0.8176 - loss: 45.3770 - val_accuracy: 0.7259 - val_loss: 44.6594 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 612ms/step - accuracy: 0.8463 - loss: 44.1399 - val_accuracy: 0.7310 - val_loss: 43.4327 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 756ms/step - accuracy: 0.8267 - loss: 42.9788 - val_accuracy: 0.7817 - val_loss: 42.1730 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 608ms/step - accuracy: 0.8722 - loss: 41.7376 - val_accuracy: 0.7716 - val_loss: 41.1037 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 587ms/step - accuracy: 0.8670 - loss: 40.5690 - val_accuracy: 0.7665 - val_loss: 39.9644 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 747ms/step - accuracy: 0.8768 - loss: 39.4123 - val_accuracy: 0.8020 - val_loss: 38.7505 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 657ms/step - accuracy: 0.8809 - loss: 38.2855 - val_accuracy: 0.8020 - val_loss: 37.5989 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 629ms/step - accuracy: 0.8682 - loss: 37.1824 - val_accuracy: 0.7513 - val_loss: 36.6628 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 796ms/step - accuracy: 0.8775 - loss: 36.1177 - val_accuracy: 0.8071 - val_loss: 35.4038 - learning_rate: 1.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 622ms/step - accuracy: 0.8859 - loss: 34.9972 - val_accuracy: 0.7614 - val_loss: 34.3723 - learning_rate: 1.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 594ms/step - accuracy: 0.9068 - loss: 33.9304 - val_accuracy: 0.7919 - val_loss: 33.3450 - learning_rate: 1.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8981 - loss: 32.9345\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 596ms/step - accuracy: 0.8975 - loss: 32.9186 - val_accuracy: 0.7970 - val_loss: 32.3774 - learning_rate: 1.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 658ms/step - accuracy: 0.8970 - loss: 32.0524 - val_accuracy: 0.7817 - val_loss: 31.8809 - learning_rate: 5.0000e-05\n",
      "Epoch 20/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 620ms/step - accuracy: 0.8940 - loss: 31.5272 - val_accuracy: 0.7970 - val_loss: 31.3820 - learning_rate: 5.0000e-05\n",
      "Epoch 21/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.9190 - loss: 31.0352\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 609ms/step - accuracy: 0.9178 - loss: 31.0288 - val_accuracy: 0.8020 - val_loss: 30.8905 - learning_rate: 5.0000e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 764ms/step - accuracy: 0.9041 - loss: 30.5949 - val_accuracy: 0.8325 - val_loss: 30.6490 - learning_rate: 2.5000e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 603ms/step - accuracy: 0.8939 - loss: 30.3888 - val_accuracy: 0.8122 - val_loss: 30.3939 - learning_rate: 2.5000e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 611ms/step - accuracy: 0.9059 - loss: 30.1153 - val_accuracy: 0.8122 - val_loss: 30.1482 - learning_rate: 2.5000e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.9257 - loss: 29.8416\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 649ms/step - accuracy: 0.9243 - loss: 29.8390 - val_accuracy: 0.8173 - val_loss: 29.9082 - learning_rate: 2.5000e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 620ms/step - accuracy: 0.8843 - loss: 29.6744 - val_accuracy: 0.8173 - val_loss: 29.8003 - learning_rate: 1.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 600ms/step - accuracy: 0.9315 - loss: 29.4930 - val_accuracy: 0.8223 - val_loss: 29.6613 - learning_rate: 1.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.9023 - loss: 29.3830\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 610ms/step - accuracy: 0.9027 - loss: 29.3821 - val_accuracy: 0.8173 - val_loss: 29.5244 - learning_rate: 1.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 636ms/step - accuracy: 0.9047 - loss: 29.3023 - val_accuracy: 0.8173 - val_loss: 29.4626 - learning_rate: 6.2500e-06\n",
      "Epoch 30/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 618ms/step - accuracy: 0.9276 - loss: 29.1942 - val_accuracy: 0.8173 - val_loss: 29.4035 - learning_rate: 6.2500e-06\n",
      "\n",
      "Elapsed time: 292.82294964790344 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [2,2,2,2] # ResNet18\n",
    "dropout_rate = 0.5 # Change HERE\n",
    "l2_lambda = 0.01 # Change HERE\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate, l2_lambda = l2_lambda)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_L2_regularizer_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 60 # Change here\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a262f29-7cfa-4701-a718-cbd92159bc40",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c50a28c6-5bc7-4bbe-ac7b-d02e5283364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - accuracy: 0.7815 - loss: 30.7805\n",
      "Test Accuracy is: 0.79%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_L2_regularizer_callbacks_trained.keras') # Loading best model\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb85b5-629a-4b60-8367-d98ba91ba2cd",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Also with L2 Regularizer, Test Accuracy is 79% (l2_lambda = 0.01), but val accuracy was now monitored with the callbacks instead the loss\n",
    "\n",
    "IMPORTANT: Because of the regularizer, the val keeps decreasing while the val accuracy not --> monitor the val_accuracy instead for the call backs! \n",
    "\n",
    "    - Try different different l2_lambda\n",
    "    - Result: None\n",
    "    - Stick with Dropout but no Regularizer\n",
    "    (Try only Regularizer and not Dropout?)\n",
    "\n",
    "To experiment with: \n",
    "\n",
    "    - Data Augmentation\n",
    "    - Different ResNet Complexities\n",
    "\n",
    "Try different ResNet Architectures: \n",
    "\n",
    "    - ResNet10: less complex \n",
    "    - ResNet50: more complex (need to use pre-trained model for ResNet50)\n",
    "    --> use the same hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a6c67-9c9c-4bba-a379-b86b80f3e576",
   "metadata": {},
   "source": [
    "## ResNet34: with Tensor Board + 46 Channels + with Dropout + ReduceLR + EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f003f66-1cbb-442c-9624-a0947eb5b41d",
   "metadata": {},
   "source": [
    "### Redefine Network Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e06577-0526-459e-8116-c682cbc94fad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3], dropout_rate = 0.5):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0290413-1e18-4651-97ec-2a65c9b47a43",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53e0769-f869-4aff-a4ef-0efa08cea084",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet34_46_dropout_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet34_46_dropout_callbacks_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633347f6-61b7-4f08-82be-26925fec51b0",
   "metadata": {},
   "source": [
    "### Train ResNet34 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be34c22-9bbd-40ab-ae47-2bcab9a3971c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 18:44:42.649948: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-16 18:44:45.203408: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734374703.590072  702277 service.cc:146] XLA service 0x7fa0d80039c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734374703.590110  702277 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-16 18:45:04.119608: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-16 18:45:06.159870: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "2024-12-16 18:45:12.934375: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1734374742.193118  702277 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;66;03m# Change here\u001b[39;00m\n\u001b[1;32m     25\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 27\u001b[0m history_ResNet18 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_ResNet34\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     32\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    915\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[1;32m    916\u001b[0m           bound_args\n\u001b[1;32m    917\u001b[0m       )\n\u001b[1;32m    918\u001b[0m   )\n\u001b[0;32m--> 919\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[1;32m    925\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/opt/tljh/user/envs/BME342_GPU_env/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [3,4,6,3] # ResNet34\n",
    "dropout_rate = 0.5 # Change HERE\n",
    "# Build Network Graph \n",
    "model_ResNet34 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet34.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet34_46_dropout_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 60 # Change here\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet34.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c151ee-e630-439f-a16b-7e92f640d6c4",
   "metadata": {},
   "source": [
    "### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42c1066a-8357-4a18-99a2-0e706f6de28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - accuracy: 0.7973 - loss: 0.5676\n",
      "Test Accuracy is: 0.81%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet34_46_dropout_callbacks_trained.keras') # Loading best model\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a33956-3bb5-4882-8cff-f9e39502a6fd",
   "metadata": {},
   "source": [
    "### Comments \n",
    "\n",
    "With ResNet34, we get almost the same test accuracy (81%) as with ResNet18\n",
    "\n",
    "Let's try ResNet10!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fdc76b-275e-4d79-a432-c7b0e009b7b8",
   "metadata": {},
   "source": [
    "## ResNet10: with Tensor Board + 46 Channels + with Dropout + ReduceLR + EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4354a-9df9-47b6-b689-5c04ea1c69cc",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2184af33-4694-443e-9071-3d52c70de8e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet10_46_dropout_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet10_46_dropout_callbacks_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17600145-7ebc-4882-afef-bd53b2d706e5",
   "metadata": {},
   "source": [
    "### Train ResNet10 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d37259e-6321-455b-b223-00f43eaff79e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 19:59:04.694482: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-16 19:59:07.257942: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734379155.637665  703976 service.cc:146] XLA service 0x7fd8a00284e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734379155.637712  703976 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-16 19:59:15.886001: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-16 19:59:16.491009: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "2024-12-16 19:59:19.403535: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1734379175.725696  703976 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.6158 - loss: 0.9499 - val_accuracy: 0.6193 - val_loss: 0.7238 - learning_rate: 1.0000e-04\n",
      "Epoch 2/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 554ms/step - accuracy: 0.6206 - loss: 0.8545 - val_accuracy: 0.6751 - val_loss: 0.6868 - learning_rate: 1.0000e-04\n",
      "Epoch 3/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 549ms/step - accuracy: 0.6894 - loss: 0.6206 - val_accuracy: 0.6701 - val_loss: 0.6339 - learning_rate: 1.0000e-04\n",
      "Epoch 4/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 557ms/step - accuracy: 0.7970 - loss: 0.4751 - val_accuracy: 0.7259 - val_loss: 0.5927 - learning_rate: 1.0000e-04\n",
      "Epoch 5/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 552ms/step - accuracy: 0.8484 - loss: 0.4014 - val_accuracy: 0.7665 - val_loss: 0.5428 - learning_rate: 1.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 575ms/step - accuracy: 0.8639 - loss: 0.3292 - val_accuracy: 0.7716 - val_loss: 0.5061 - learning_rate: 1.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 454ms/step - accuracy: 0.8531 - loss: 0.3350 - val_accuracy: 0.7766 - val_loss: 0.5139 - learning_rate: 1.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 515ms/step - accuracy: 0.8745 - loss: 0.3352 - val_accuracy: 0.8020 - val_loss: 0.4663 - learning_rate: 1.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 435ms/step - accuracy: 0.8550 - loss: 0.3208 - val_accuracy: 0.7868 - val_loss: 0.5492 - learning_rate: 1.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 534ms/step - accuracy: 0.8846 - loss: 0.2642 - val_accuracy: 0.7919 - val_loss: 0.4622 - learning_rate: 1.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 531ms/step - accuracy: 0.8948 - loss: 0.2824 - val_accuracy: 0.8122 - val_loss: 0.4519 - learning_rate: 1.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 466ms/step - accuracy: 0.8990 - loss: 0.2373 - val_accuracy: 0.8020 - val_loss: 0.4811 - learning_rate: 1.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 443ms/step - accuracy: 0.8903 - loss: 0.2294 - val_accuracy: 0.8477 - val_loss: 0.4715 - learning_rate: 1.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.9147 - loss: 0.2193\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 455ms/step - accuracy: 0.9135 - loss: 0.2220 - val_accuracy: 0.7970 - val_loss: 0.6689 - learning_rate: 1.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 539ms/step - accuracy: 0.9057 - loss: 0.2156 - val_accuracy: 0.8477 - val_loss: 0.4188 - learning_rate: 5.0000e-05\n",
      "Epoch 16/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 462ms/step - accuracy: 0.9074 - loss: 0.2339 - val_accuracy: 0.8173 - val_loss: 0.4694 - learning_rate: 5.0000e-05\n",
      "Epoch 17/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 461ms/step - accuracy: 0.9120 - loss: 0.2083 - val_accuracy: 0.8274 - val_loss: 0.4293 - learning_rate: 5.0000e-05\n",
      "Epoch 18/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9129 - loss: 0.2140\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 454ms/step - accuracy: 0.9125 - loss: 0.2158 - val_accuracy: 0.8376 - val_loss: 0.4646 - learning_rate: 5.0000e-05\n",
      "Epoch 19/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 465ms/step - accuracy: 0.9091 - loss: 0.2264 - val_accuracy: 0.8274 - val_loss: 0.4392 - learning_rate: 2.5000e-05\n",
      "Epoch 20/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 451ms/step - accuracy: 0.9105 - loss: 0.2246 - val_accuracy: 0.8376 - val_loss: 0.4214 - learning_rate: 2.5000e-05\n",
      "Epoch 21/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.9274 - loss: 0.1927\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 462ms/step - accuracy: 0.9269 - loss: 0.1934 - val_accuracy: 0.8274 - val_loss: 0.4352 - learning_rate: 2.5000e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 482ms/step - accuracy: 0.9406 - loss: 0.1816 - val_accuracy: 0.8376 - val_loss: 0.4290 - learning_rate: 1.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 476ms/step - accuracy: 0.9362 - loss: 0.1766 - val_accuracy: 0.8274 - val_loss: 0.4345 - learning_rate: 1.2500e-05\n",
      "\n",
      "Elapsed time: 179.0483593940735 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [1,1,1,1] # ResNet10\n",
    "dropout_rate = 0.5 # Change HERE\n",
    "# Build Network Graph \n",
    "model_ResNet10 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet10.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet10_46_dropout_callbacks_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 60 # Change here\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet10.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b4ca4-2aba-4fc0-a730-b57e21569bb8",
   "metadata": {},
   "source": [
    "### Training Accuracy ResNet10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a47721-0b28-4f1f-9ea1-99a8eb5c2b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.7730 - loss: 0.5733\n",
      "Test Accuracy is: 0.79%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet10_46_dropout_callbacks_trained.keras') # Loading best model\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e43b73-8219-4aba-b4f1-1b7c6e3d7688",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "ResNet10 provides 79% accuracy on the test set, while ResNet18 with dropout provides 81% (best model) --> keep ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f3a43-7330-4659-8596-9a52a9e142e7",
   "metadata": {},
   "source": [
    "## ResNet18: with Tensor Board + 46 Channels + with Dropout + ReduceLR + EarlyStopping + Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5a813-14fb-452e-ac99-186909cc32c5",
   "metadata": {},
   "source": [
    "### Redefine Network with Dropout and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a933bc4-2c48-474d-b9cd-0613310ec7f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3], dropout_rate = 0.5):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    # Data Augmentation\n",
    "    x = RandomFlip(mode = \"horizontal_and_vertical\", seed = None)(x_input)\n",
    "    x = RandomRotation(factor = 0.2, interpolation = \"nearest\")(x)\n",
    "    # Proceed with Model \n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5bc032-27cc-436f-afa6-1533b673c923",
   "metadata": {},
   "source": [
    "### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f4f174-0852-4b38-b0c2-6077067b09b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_callbacks_augmentation_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet18_46_dropout_callbacks_augmentation_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d585b2-4c95-4690-91b6-f81accc461fe",
   "metadata": {},
   "source": [
    "### Training ResNet18 model with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b889c7f1-cbcc-4fa6-b554-8d0b7b5ff9f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 21:58:35.584670: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-16 21:58:38.205931: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 21:58:48.899855: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/ResNet34_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "W0000 00:00:1734386331.217668  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386331.330188  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386331.418583  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386331.618094  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386331.679775  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386331.747881  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-12-16 21:58:51.791917: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1734386331.791982  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.420981  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.424851  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.428313  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.431264  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.434070  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.436978  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.440243  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.443434  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.448895  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.453704  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.457677  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.461646  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.466963  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.472131  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.486800  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.494787  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.524107  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.542210  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.544500  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.546842  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.549373  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.552136  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.555149  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.558164  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.561402  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.564798  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.567156  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.571940  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.576439  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.581935  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.589024  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.590419  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.591653  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.592882  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.594320  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.595843  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.597336  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.598829  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.600549  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.602195  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.603552  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.605008  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.610178  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.612981  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.615640  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.618424  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.621501  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.625014  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.628464  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.632014  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.635784  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.639682  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.644106  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.648518  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.653061  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.657795  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.665313  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.673149  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.685580  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.697814  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.699051  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.700126  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.701685  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.703116  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.704546  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.705869  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.707485  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.709141  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.710295  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.711591  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.715550  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.717938  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.720362  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.722910  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.725849  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.728043  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.730824  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.733834  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.736848  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.739500  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.742653  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.747378  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.752111  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.759337  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.761645  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.768473  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.771576  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.775564  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.779595  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.783753  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.788054  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.792660  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.797337  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.802182  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.807225  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.812251  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.817406  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.824038  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.832312  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.844548  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.853473  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.856480  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.859425  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.862565  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.865509  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.869092  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.872609  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.876498  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.880388  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.884300  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.889686  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.903517  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.904830  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.905926  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.907026  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.908266  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.909601  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.910784  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.912042  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.913334  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.914638  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.916179  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.917673  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.922718  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.924974  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.930691  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.935218  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.939603  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.944552  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.949074  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.954085  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.960865  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.965597  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.971114  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.976816  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.986001  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386332.990915  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.000531  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.006481  707518 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.495075  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.496975  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.500726  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.509536  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.514267  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.522497  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.528387  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.534487  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.543913  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.552367  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.560538  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.572771  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.587180  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.590746  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.597779  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.603395  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.608388  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.613867  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.631378  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.652514  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.674894  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.682649  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.693401  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.703489  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.713214  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.715577  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.716980  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.718862  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.720597  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.722339  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.724151  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.726292  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.756043  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.757596  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.759251  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.760954  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.780703  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.789787  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.792836  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.797480  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.801185  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.804911  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.809401  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.814003  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.819329  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.825379  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.832402  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.838346  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.842624  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.851946  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.863794  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.876934  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.923163  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.931489  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.937288  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.943821  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.949983  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.957924  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.965448  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.972954  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.982178  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.990987  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386333.998902  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.009048  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.020901  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.023623  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.030311  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.033266  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.037214  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.041425  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.046465  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.052944  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.059460  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.066436  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.074715  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.083985  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.092437  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.094646  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.095875  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.097740  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.099238  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.100738  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.102418  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.104573  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.125790  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.127428  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.128691  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.148322  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.157256  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.160216  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.162941  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.166277  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.169500  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.172775  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.177097  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.181354  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.186619  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.192741  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.197721  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.201646  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.206012  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.210045  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.214679  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.229088  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.237778  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.242106  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.245460  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.253141  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.259194  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.267061  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.275892  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.281672  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.287742  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.296917  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.304563  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.314143  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.318097  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.321271  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.323945  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.326618  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.330356  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.333126  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.337219  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.343242  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.349606  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.357202  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.366789  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.379612  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.381004  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.383059  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.385265  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.386999  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.388749  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.390425  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.392311  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.407599  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.410406  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.411913  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.432159  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.446321  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.449304  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.452444  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.455866  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.459594  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.463492  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.468836  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.474351  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.479538  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.485392  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.492498  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.497678  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.502090  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.507474  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.511724  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.518886  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.534650  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.539805  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.546180  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.554264  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.561222  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.569932  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.579398  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.589893  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.601387  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.611177  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.625346  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.641420  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.648604  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.651980  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.655529  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.659059  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.662641  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.668129  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.675113  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.682483  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.689982  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.697680  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.714294  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.866158  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386334.963723  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386335.073207  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386335.197405  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386335.322545  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386335.436394  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386335.583108  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386335.721931  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386335.911254  707516 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.5530 - loss: 1.5265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1734386340.834708  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386340.848433  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386340.858831  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386340.904119  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386340.917456  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386340.930634  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386340.944664  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386340.989088  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.024591  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.039873  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.041457  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.043108  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.044784  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.046807  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.048578  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.050337  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.052190  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.054044  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.055839  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.057991  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.060791  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.062565  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.064944  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.068079  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.075710  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.080768  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.081865  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.082988  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.084150  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.085287  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.086493  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.087861  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.089117  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.090380  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.091688  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.093236  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.095010  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.096511  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.100956  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.101791  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.102609  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.103413  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.104246  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.105084  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.105931  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.106821  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.107707  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.108593  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.109455  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.110339  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.111325  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.116535  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.117710  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.118885  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.120165  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.121469  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.122953  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.124293  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.125675  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.127143  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.128611  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.130116  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.131486  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.133290  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.134920  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.136865  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.139417  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.144730  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.145651  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.146395  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.147152  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.147921  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.148659  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.149424  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.150179  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.150935  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.151766  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.152541  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.153384  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.154178  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.158338  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.159463  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.160671  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.161874  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.163063  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.164168  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.165200  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.166262  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.167374  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.168417  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.169633  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.171120  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.172525  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.178133  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.179196  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.180281  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.181603  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.182971  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.184447  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.185813  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.187169  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.188583  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.190117  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.191660  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.193139  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.194818  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.198482  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.200415  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.202802  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.210692  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.211811  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.213303  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.214502  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.215971  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.217165  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.218434  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.219706  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.220902  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.222134  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.223395  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.224535  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.225844  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.234837  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.235607  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.236361  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.237133  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.237908  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.238696  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.239486  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.240256  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.241031  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.241803  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.242576  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.243511  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.244308  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.255212  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.256551  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.258139  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.259740  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.261237  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.262933  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.264516  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.266022  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.267731  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.269302  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.270882  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.272437  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.274238  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.286192  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.288327  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.290570  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.302607  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.304018  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.305787  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.308405  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.310223  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.312681  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.314921  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.317083  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.319592  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.321868  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.325854  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.328534  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.333330  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.334590  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.339419  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.341201  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.343007  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.344848  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.348779  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.361329  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.373801  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.375683  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.378221  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.382219  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.386763  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.387689  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.388715  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.389706  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.390687  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.391684  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.392697  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.393805  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.396442  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.397384  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.398469  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.403224  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.406458  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.410685  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.412030  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.413683  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.415184  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.416795  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.418387  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.420023  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.421721  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.423516  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.426140  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.427763  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.429122  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.431454  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.438133  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.446736  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.470986  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.502487  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.503966  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.505663  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.507493  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.509303  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.511391  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.513523  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.515692  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.518189  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.520589  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.524732  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.527588  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.531763  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.532913  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.537499  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.538735  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.540211  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.541926  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.543535  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.547297  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.551059  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.552946  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.555112  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.558670  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.560677  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.562311  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.563106  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.564495  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.565357  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.566195  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.567194  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.568283  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.571113  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.571959  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.572799  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.579238  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.581023  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.582531  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.583696  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.585056  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.586317  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.587582  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.589201  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.590624  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.592262  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.594614  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.595891  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.597205  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.598594  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.600890  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.603712  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.610239  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.634642  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.636046  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.637448  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.639500  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.641237  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.642956  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.645256  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.647446  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.649854  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.651959  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.654019  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.656782  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.659970  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.661154  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.662345  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.663967  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.665599  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.666940  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.668750  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.670264  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.672018  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.673813  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.675862  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.679552  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.682153  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.682998  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.684593  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.686400  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.687280  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.688120  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.689193  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.690395  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.692401  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.693370  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.694254  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.700621  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.703221  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.704412  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.705951  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.707215  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.708563  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.709932  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.711672  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.713293  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.714925  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.717174  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.718546  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.719868  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.721470  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.723622  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.726136  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.729028  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.752164  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.754893  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.756417  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.758473  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.760319  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.762795  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.765123  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.767433  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.769908  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.772810  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.775981  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.780722  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.784922  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.786419  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.787721  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.789341  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.790957  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.792274  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.795009  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.797068  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.799146  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.801169  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.803223  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.810158  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.839345  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.856346  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.880532  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.910938  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.939131  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.962230  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386341.999085  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386342.031831  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386342.075511  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645ms/step - accuracy: 0.5511 - loss: 1.5232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1734386346.020382  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.024902  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.030038  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.038371  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.053880  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.069498  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.073740  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.082184  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.084559  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.085592  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.086650  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.087738  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.088817  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.089911  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.091002  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.092111  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.093252  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.094533  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.095977  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.097286  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.098958  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.100402  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.102269  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.109086  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.109967  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.110829  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.111709  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.112593  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.113448  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.114347  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.115376  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.116304  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.117233  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.118168  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.119191  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.120285  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.123569  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.124339  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.125090  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.125847  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.126562  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.127296  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.128069  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.128778  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.129484  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.130192  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.130917  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.131676  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.132395  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.136424  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.137310  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.138256  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.139189  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.140184  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.141129  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.142036  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.143020  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.144001  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.144967  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.145950  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.147024  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.148206  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.149301  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.150583  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.152010  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.155300  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.159396  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.160235  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.161081  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.161923  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.162763  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.163626  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.164433  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.165230  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.166133  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.166933  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.167833  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.168786  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.171944  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.172622  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.173300  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.173964  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.174631  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.175315  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.176011  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.176697  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.177364  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.178042  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.178714  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.179456  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.180129  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.184070  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.185002  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.185924  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.186716  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.187630  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.188559  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.189499  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.190459  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.191428  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.192425  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.193453  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.194562  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.195675  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.196879  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.198017  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.201441  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.205619  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.211613  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.212557  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.213479  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.214427  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.215315  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.216282  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.217250  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.218158  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.219092  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.220032  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.221137  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.222163  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.225574  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.226278  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.226952  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.227620  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.228295  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.228978  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.229661  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.230351  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.231040  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.231736  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.232521  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.233206  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.233901  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.237939  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.239368  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.240555  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.241674  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.242907  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.243925  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.245485  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.246657  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.248285  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.249556  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.250816  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.252011  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.253276  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.254419  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.255540  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.260318  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386346.264087  707512 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.5495 - loss: 1.5204 - val_accuracy: 0.4010 - val_loss: 0.9745 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 793ms/step - accuracy: 0.6330 - loss: 0.8855 - val_accuracy: 0.3858 - val_loss: 1.0615 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 950ms/step - accuracy: 0.6722 - loss: 0.6857 - val_accuracy: 0.6244 - val_loss: 0.7681 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 808ms/step - accuracy: 0.6920 - loss: 0.6313 - val_accuracy: 0.5939 - val_loss: 0.7929 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 966ms/step - accuracy: 0.7005 - loss: 0.6094 - val_accuracy: 0.6497 - val_loss: 0.7335 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 929ms/step - accuracy: 0.7653 - loss: 0.5344 - val_accuracy: 0.7005 - val_loss: 0.6612 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.7889 - loss: 0.5045 - val_accuracy: 0.6802 - val_loss: 0.6797 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 937ms/step - accuracy: 0.8400 - loss: 0.4164 - val_accuracy: 0.6954 - val_loss: 0.6431 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 955ms/step - accuracy: 0.8636 - loss: 0.3420 - val_accuracy: 0.7411 - val_loss: 0.5966 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 967ms/step - accuracy: 0.8547 - loss: 0.3695 - val_accuracy: 0.7614 - val_loss: 0.5883 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 937ms/step - accuracy: 0.8044 - loss: 0.4188 - val_accuracy: 0.8122 - val_loss: 0.4836 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 803ms/step - accuracy: 0.8761 - loss: 0.3218 - val_accuracy: 0.8071 - val_loss: 0.5120 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 768ms/step - accuracy: 0.8783 - loss: 0.3071 - val_accuracy: 0.8223 - val_loss: 0.5410 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518ms/step - accuracy: 0.8983 - loss: 0.2626\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 789ms/step - accuracy: 0.8966 - loss: 0.2682 - val_accuracy: 0.8325 - val_loss: 0.5580 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 784ms/step - accuracy: 0.8402 - loss: 0.3842 - val_accuracy: 0.8223 - val_loss: 0.5203 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 937ms/step - accuracy: 0.8963 - loss: 0.3045 - val_accuracy: 0.8223 - val_loss: 0.4761 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 818ms/step - accuracy: 0.9027 - loss: 0.2747 - val_accuracy: 0.8173 - val_loss: 0.5272 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 800ms/step - accuracy: 0.9058 - loss: 0.2463 - val_accuracy: 0.8274 - val_loss: 0.5104 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - accuracy: 0.8884 - loss: 0.2613\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811ms/step - accuracy: 0.8881 - loss: 0.2619 - val_accuracy: 0.8274 - val_loss: 0.5742 - learning_rate: 5.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 814ms/step - accuracy: 0.8983 - loss: 0.2672 - val_accuracy: 0.8274 - val_loss: 0.5657 - learning_rate: 2.5000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 820ms/step - accuracy: 0.8880 - loss: 0.2715 - val_accuracy: 0.8173 - val_loss: 0.5198 - learning_rate: 2.5000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.8964 - loss: 0.2734\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 808ms/step - accuracy: 0.8955 - loss: 0.2729 - val_accuracy: 0.8122 - val_loss: 0.6013 - learning_rate: 2.5000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 794ms/step - accuracy: 0.9037 - loss: 0.2222 - val_accuracy: 0.8223 - val_loss: 0.5414 - learning_rate: 1.2500e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 819ms/step - accuracy: 0.8800 - loss: 0.2825 - val_accuracy: 0.8071 - val_loss: 0.5272 - learning_rate: 1.2500e-05\n",
      "\n",
      "Elapsed time: 244.12225604057312 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [2,2,2,2] # ResNet18\n",
    "dropout_rate = 0.5\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_callbacks_augmentation_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d78df-28c1-4dd0-b417-37546afabee9",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac7c82da-ba33-475b-8c97-794860cebd5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1734386590.772684  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386590.825863  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386590.870674  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386590.999930  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.038402  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.076850  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.099678  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.188648  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.263135  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.288286  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.290628  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.292894  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.295245  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.297647  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.300242  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.302834  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.306646  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.309848  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.312654  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.315454  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.319129  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.322115  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.329790  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.334063  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.342856  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.353245  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.354807  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.356422  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.358130  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.359967  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.361913  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.363868  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.365929  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.368065  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.369648  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.372369  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.375011  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.378101  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.383192  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.384164  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.385172  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.386175  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.387286  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.388414  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.389540  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.390655  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.391883  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.393067  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.394111  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.395218  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.399554  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.401302  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.403272  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.405457  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.407414  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.409566  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.411628  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.413787  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.416002  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.418477  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.420900  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.423319  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.425833  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.427901  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.431685  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.436378  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.442983  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.447306  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.449220  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.451222  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.453276  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.454789  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.456368  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.458032  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.459864  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.461473  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.463234  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7812 - loss: 0.6515"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1734386591.466036  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.468763  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.473688  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.474636  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.475575  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.476443  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.477433  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.478351  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.479276  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.480268  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.481312  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.482456  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.483397  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.484428  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.488533  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.490023  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.495106  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.496850  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.498957  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.501135  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.503374  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.505642  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.508065  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.510545  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.513063  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.515744  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.518422  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.521152  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.525360  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.529408  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.536861  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.539836  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.541735  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.543675  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.545615  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.547546  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.549638  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.551745  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.554015  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.556290  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.558599  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.561577  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.564670  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.574365  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.575254  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.576128  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.577017  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.577928  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.578919  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.579822  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.580729  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.581645  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.582559  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.583520  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.584646  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.588709  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.590299  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.593298  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.596035  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.598729  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.601606  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.604402  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.607153  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.612488  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.615166  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.618067  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.620969  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.625400  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.627914  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.632602  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734386591.635769  707510 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.8137 - loss: 0.5284 \n",
      "Test Accuracy is: 0.81%\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_callbacks_augmentation_trained.keras') # Loading best model\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e39805-b349-4320-9bdc-92ef59f4371b",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "After Data Augmentation (RandomFlip and RandomRotation, the Testing accuracy is 81%, almost the same as before. For simplicity, we will leave out Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236c67f-ad78-4024-962a-1bf4169b60cb",
   "metadata": {},
   "source": [
    "## ResNet18: with Tensor Board + 46 Channels + with Dropout + ReduceLR + EarlyStopping + In Layer Rescaling \n",
    "\n",
    "For the sake of clarity, we want to normalize the data with \"x = layers.Rescaling(1./255)(x)\" in layer instead of pre-processing the data and standardizing with mean = 0 & std = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9dec836-3c02-4b10-ba7f-20be7f63ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data set: without normalization\n",
    "X_train, y_train = load_dataset(train_df, image_folder, normalize = False)\n",
    "X_val, y_val = load_dataset(val_df, image_folder, normalize = False)\n",
    "X_test, y_test = load_dataset(test_df, image_folder, normalize = False)\n",
    "\n",
    "# # One-hot Encoding\n",
    "# y_train= to_categorical(y_train)\n",
    "# y_val= to_categorical(y_val)\n",
    "# y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7933eec-458c-49bd-8e0b-c1dd4249604b",
   "metadata": {},
   "source": [
    "### Redefine network architecture with in layer rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559bd87d-ea69-4206-a451-4e2f299f532f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def identity_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3], dropout_rate = 0.5):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    # Rescaling Layer (in-layer)\n",
    "    x = layers.Rescaling(1./255)(x_input)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8336835b-0e9c-4ce1-9c2d-c59f5df28c9e",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415f3b1b-2702-4ad7-8b60-7ade98dcee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_callbacks_layer_rescaling_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet18_46_dropout_callbacks_layer_rescaling_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294a093-8e39-437b-a5bd-488cae570a9f",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7906448-9ea7-416b-8b61-0bff08070a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 20:53:05.601589: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-17 20:53:08.207689: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734468800.011273  735905 service.cc:146] XLA service 0x7f51cc04a950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734468800.011327  735905 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-17 20:53:20.326613: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-17 20:53:21.392947: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "2024-12-17 20:53:24.945075: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1734468824.923963  735905 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3s/step - accuracy: 0.5580 - loss: 1.8411 - val_accuracy: 0.6396 - val_loss: 0.6870 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 747ms/step - accuracy: 0.5664 - loss: 1.0095 - val_accuracy: 0.6396 - val_loss: 0.6814 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 734ms/step - accuracy: 0.5392 - loss: 0.8558 - val_accuracy: 0.6396 - val_loss: 0.6767 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 745ms/step - accuracy: 0.6375 - loss: 0.8148 - val_accuracy: 0.6396 - val_loss: 0.6667 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 759ms/step - accuracy: 0.6065 - loss: 0.7273 - val_accuracy: 0.6396 - val_loss: 0.6622 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 734ms/step - accuracy: 0.6269 - loss: 0.6962 - val_accuracy: 0.6396 - val_loss: 0.6588 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 599ms/step - accuracy: 0.6457 - loss: 0.6867 - val_accuracy: 0.6396 - val_loss: 0.6668 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 592ms/step - accuracy: 0.6166 - loss: 0.7000 - val_accuracy: 0.6396 - val_loss: 0.6598 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.6717 - loss: 0.6445\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 586ms/step - accuracy: 0.6692 - loss: 0.6473 - val_accuracy: 0.6396 - val_loss: 0.6590 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 602ms/step - accuracy: 0.6666 - loss: 0.6581 - val_accuracy: 0.6396 - val_loss: 0.6656 - learning_rate: 5.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 715ms/step - accuracy: 0.6577 - loss: 0.6227 - val_accuracy: 0.6396 - val_loss: 0.6563 - learning_rate: 5.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 614ms/step - accuracy: 0.6426 - loss: 0.6424 - val_accuracy: 0.6396 - val_loss: 0.6587 - learning_rate: 5.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 790ms/step - accuracy: 0.6510 - loss: 0.6427 - val_accuracy: 0.6396 - val_loss: 0.6551 - learning_rate: 5.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 626ms/step - accuracy: 0.6656 - loss: 0.6391 - val_accuracy: 0.6396 - val_loss: 0.6631 - learning_rate: 5.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 628ms/step - accuracy: 0.6649 - loss: 0.6433 - val_accuracy: 0.6396 - val_loss: 0.6667 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.6878 - loss: 0.6540\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 628ms/step - accuracy: 0.6858 - loss: 0.6532 - val_accuracy: 0.6396 - val_loss: 0.6631 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 603ms/step - accuracy: 0.6338 - loss: 0.6390 - val_accuracy: 0.6396 - val_loss: 0.6663 - learning_rate: 2.5000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 613ms/step - accuracy: 0.6551 - loss: 0.6274 - val_accuracy: 0.6396 - val_loss: 0.6645 - learning_rate: 2.5000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.6892 - loss: 0.6168\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 638ms/step - accuracy: 0.6872 - loss: 0.6180 - val_accuracy: 0.6396 - val_loss: 0.6619 - learning_rate: 2.5000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 627ms/step - accuracy: 0.6816 - loss: 0.6108 - val_accuracy: 0.6396 - val_loss: 0.6630 - learning_rate: 1.2500e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 643ms/step - accuracy: 0.6444 - loss: 0.6457 - val_accuracy: 0.6396 - val_loss: 0.6662 - learning_rate: 1.2500e-05\n",
      "\n",
      "Elapsed time: 247.5635483264923 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 46\n",
    "CLASSES = 2\n",
    "block_layers = [2,2,2,2] # ResNet18\n",
    "dropout_rate = 0.5\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate)\n",
    "\n",
    "# Compile Model\n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_callbacks_layer_rescaling_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 30\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebec668-dc3f-45b5-b6f9-0eb4ecf79773",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ab4aa3-50eb-42d0-af2c-57e47a0d2602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - accuracy: 0.6209 - loss: 0.6635\n",
      "Test Accuracy is: 0.63%\n"
     ]
    }
   ],
   "source": [
    "# To load the model from file uncomment and run the following \n",
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_callbacks_layer_rescaling_trained.keras')\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32e6168-9af4-4c1e-9102-4c8a00db7974",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2033874-91e5-4529-b996-202ec8d1a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred_test = loaded_model.predict(X_test)\n",
    "y_pred_test = (y_pred_test < 0.5).astype(int)\n",
    "f1 = f1_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804a7d14-7923-4ed7-a6f8-bdd2a776b129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5353159851301115\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee9373-02b4-4abd-8f72-39e0af012605",
   "metadata": {},
   "source": [
    "### Comments \n",
    "\n",
    "Very interesting: Without normalizing the images to mean = 0 and std = 1, but rescaling with layers.Rescaling (with range [0,1]), the mode fails to extract meaningfull information and only predicts one class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9cd3eb-e4dc-45d2-a345-2194999e2aee",
   "metadata": {},
   "source": [
    "#### Future improvements to make: \n",
    "\n",
    "    - Vary the neurons of the last Dense layer before classification: 512 --> (128, 256, 1024, 2048 etc)\n",
    "    - Cross-Validation\n",
    "    - Use Balanced Dataset maybe?\n",
    "    - Use pre-trained ResNet and train only some unfrozen layers\n",
    "    - Channel selection\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BME342 Env",
   "language": "python",
   "name": "bme342_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
