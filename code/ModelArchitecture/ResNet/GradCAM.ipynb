{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a846b379-64ef-4349-ba38-38ebf1759216",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ecf68a-d0e7-4976-9eee-5f4ecd3dea69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 09:20:28.315201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-20 09:20:28.329834: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-20 09:20:28.334314: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-20 09:20:28.345452: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled. Checking for available GPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734686432.084308  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "\n",
      "Verifying TensorFlow and PyTorch CUDA setup...\n",
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: True\n",
      "Num GPUs Available: 1\n",
      "\n",
      "Keras version: 3.6.0\n",
      "\n",
      "End checks and initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734686432.124235  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734686432.127712  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734686432.133183  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734686432.136528  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734686432.139759  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734686432.745686  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734686432.747676  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734686432.749492  987826 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-20 09:20:32.751272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13312 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import helper as hp \n",
    "hp.initialize_notebook() # initialize with GPU enabled  \n",
    "# hp.initialize_notebook(False) # to disable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee06ff90-717c-4b2f-af9a-0943c9e6fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras\n",
    "# Import DL libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout # General Layers\n",
    "from keras.layers import RandomRotation, RandomFlip\n",
    "from keras import layers, models, Model, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "# Suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Import image libraries\n",
    "from skimage import transform\n",
    "import tifffile as tiff\n",
    "from tifffile import imread\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "# Appends current working dir\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64ae39a0-3ee6-492a-8c92-188538eb2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a14843-c42f-4b44-9fa2-bbf0406f55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/home/jupyter-luvogt/Final_Project_LR/IMC_images' \n",
    "metadata_dir = '/home/jupyter-luvogt/Final_Project_LR/metadata.csv'\n",
    "# --- Load CSV and filter dataset ---\n",
    "csv_file = metadata_dir\n",
    "image_folder = images_dir\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "# Filter rows with NA in PDL1_score and convert to binary\n",
    "df = df.dropna(subset=[\"PDL1_score\"])\n",
    "df[\"PDL1_score\"] = df[\"PDL1_score\"].astype(int)\n",
    "# --- Train-Test-Validation Split ---\n",
    "train_df, val_and_test_df = train_test_split(df, test_size=0.4, random_state=42, stratify=df[\"PDL1_score\"])\n",
    "test_df, val_df = train_test_split(val_and_test_df, test_size=0.5, random_state=42, stratify=val_and_test_df[\"PDL1_score\"])\n",
    "# --- Load Images and Compute Mean and Standard Deviation ---\n",
    "# Function to load a single image\n",
    "def load_image(image_path):\n",
    "    image = imread(image_path)  # Load all 46 channels\n",
    "    return image.astype(np.float32)\n",
    "# Initialize variables to accumulate sum and sum of squares\n",
    "nr_images = 0\n",
    "sum_images = np.zeros((46, 224, 224))\n",
    "sum_squared_images = np.zeros((46, 224, 224))\n",
    "# Accumulate the sum and sum of squares for the training dataset\n",
    "for _, row in train_df.iterrows():\n",
    "    image_path = os.path.join(image_folder, f\"{row['sample_id']}.tiff\")\n",
    "    image = load_image(image_path)\n",
    "    nr_images += 1\n",
    "    sum_images += image\n",
    "    sum_squared_images += image ** 2\n",
    "\n",
    "# Compute mean and standard deviation\n",
    "mean = sum_images / nr_images\n",
    "std = np.sqrt(sum_squared_images / nr_images - mean ** 2)\n",
    "\n",
    "def load_dataset(dataframe, image_folder, normalize = True): # augment = False\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        image_path = os.path.join(image_folder, f\"{row['sample_id']}.tiff\")\n",
    "        image = load_image(image_path)\n",
    "        if normalize:\n",
    "            image = (image - mean) / std\n",
    "        # Convert to channels-last format (224, 224, 46)\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        images.append(image)\n",
    "        labels.append(row[\"PDL1_score\"])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c01c64-9a15-4013-8373-847a1d79e91a",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ff4fb1-6bef-498c-9115-e2fe32ffe143",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ResNet18 = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_callbacks_sigmoid_trained.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7656c4-2b36-43a2-a4af-f8b8cbe28f45",
   "metadata": {},
   "source": [
    "### Get 2nd last layer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d45e8e9b-0c5b-4f9b-8b92-6f1059f8741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "print(model_ResNet18.layers[-3].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "626f752a-4c1b-4657-9795-6069491f68b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer_1\n",
      "zero_padding2d_1\n",
      "conv2d_20\n",
      "batch_normalization_17\n",
      "dropout_10\n",
      "activation_17\n",
      "max_pooling2d_1\n",
      "conv2d_21\n",
      "batch_normalization_18\n",
      "dropout_11\n",
      "activation_18\n",
      "conv2d_22\n",
      "batch_normalization_19\n",
      "add_8\n",
      "activation_19\n",
      "conv2d_23\n",
      "batch_normalization_20\n",
      "dropout_12\n",
      "activation_20\n",
      "conv2d_24\n",
      "batch_normalization_21\n",
      "add_9\n",
      "activation_21\n",
      "conv2d_25\n",
      "batch_normalization_22\n",
      "dropout_13\n",
      "activation_22\n",
      "conv2d_26\n",
      "batch_normalization_23\n",
      "conv2d_27\n",
      "add_10\n",
      "activation_23\n",
      "conv2d_28\n",
      "batch_normalization_24\n",
      "dropout_14\n",
      "activation_24\n",
      "conv2d_29\n",
      "batch_normalization_25\n",
      "add_11\n",
      "activation_25\n",
      "conv2d_30\n",
      "batch_normalization_26\n",
      "dropout_15\n",
      "activation_26\n",
      "conv2d_31\n",
      "batch_normalization_27\n",
      "conv2d_32\n",
      "add_12\n",
      "activation_27\n",
      "conv2d_33\n",
      "batch_normalization_28\n",
      "dropout_16\n",
      "activation_28\n",
      "conv2d_34\n",
      "batch_normalization_29\n",
      "add_13\n",
      "activation_29\n",
      "conv2d_35\n",
      "batch_normalization_30\n",
      "dropout_17\n",
      "activation_30\n",
      "conv2d_36\n",
      "batch_normalization_31\n",
      "conv2d_37\n",
      "add_14\n",
      "activation_31\n",
      "conv2d_38\n",
      "batch_normalization_32\n",
      "dropout_18\n",
      "activation_32\n",
      "conv2d_39\n",
      "batch_normalization_33\n",
      "add_15\n",
      "activation_33\n",
      "average_pooling2d_1\n",
      "flatten_1\n",
      "dense_2\n",
      "dropout_19\n",
      "dense_3\n"
     ]
    }
   ],
   "source": [
    "for layer in model_ResNet18.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b85a5a8-cd2c-4159-bac7-479e252dd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Image Path\n",
    "image_path = '/home/jupyter-luvogt/Final_Project_LR/IMC_images/ZTMA20.1_Block1_SE_007.tiff'\n",
    "image = load_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72be6408-ed61-4cf4-aa7b-290aa60126bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.transpose(image, (1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "693d49f5-a587-473a-b9ca-499106f91dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 46)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0e2b6-d23a-4f00-9563-0076d6c39481",
   "metadata": {},
   "source": [
    "## GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dcbec94-b382-463b-9766-a5239ba1cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_builder = keras.applications.xception.Xception\n",
    "img_size = (224, 224)\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"conv2d_39\"\n",
    "\n",
    "# # The local path to our target image\n",
    "# img_path = keras.utils.get_file(\n",
    "#     \"african_elephant.jpg\", \"https://i.imgur.com/Bvro0YD.png\"\n",
    "# )\n",
    "\n",
    "# display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78b693a8-3973-4a9c-90ad-bbf568d89f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.utils.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.utils.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fa751ec-5f7b-4587-afb3-b6c222f004dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "# img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
    "img_array = preprocess_input(image)\n",
    "img_array = np.expand_dims(img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93c28fdb-dc62-41c4-8349-b9f7dad36b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 46)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "680c6284-2c4d-4e1d-ad53-c713aa944f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_array = img_array[:, :, :, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1131b61f-e443-4f27-8b20-d2272bea2743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make model\n",
    "# model = model_builder(weights=\"imagenet\")\n",
    "\n",
    "# Remove last layer's softmax / sigmoid\n",
    "model_ResNet18.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = model_ResNet18.predict(img_array)\n",
    "# print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(img_array, model_ResNet18, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1baecb24-f963-4b32-84b1-bf8224874f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.utils.load_img(img_path)\n",
    "    img = keras.utils.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = mpl.colormaps[\"jet\"]\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(image_path, heatmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BME342 Env",
   "language": "python",
   "name": "bme342_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
