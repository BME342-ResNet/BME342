{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77441ad-99ed-4a60-a710-ed5f90778fef",
   "metadata": {},
   "source": [
    "### ResNet50 Trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b65e0-6e1e-4465-b8e3-6bb02d225f0c",
   "metadata": {},
   "source": [
    "### Initialize Notebook & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5cf8d2-e592-4314-9f9d-f9034cbf1b0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 12:38:24.060541: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-14 12:38:24.075118: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-14 12:38:24.079609: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-14 12:38:24.090860: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled. Checking for available GPUs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734179905.993344  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734179906.036026  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734179906.039621  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734179906.045308  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "\n",
      "Verifying TensorFlow and PyTorch CUDA setup...\n",
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: True\n",
      "Num GPUs Available: 1\n",
      "\n",
      "Keras version: 3.6.0\n",
      "\n",
      "End checks and initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734179906.048751  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734179906.052000  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734179906.240596  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734179906.242359  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734179906.243934  636814 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-14 12:38:26.245467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13312 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import helper as hp \n",
    "hp.initialize_notebook() # initialize with GPU enabled  \n",
    "# hp.initialize_notebook(False) # to disable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "350726ef-1106-4639-b36d-bf68e7aa74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras\n",
    "# Import DL libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras import layers, models, Model, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.callbacks import TensorBoard \n",
    "\n",
    "# Suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Import image libraries\n",
    "from skimage import transform\n",
    "import tifffile as tiff\n",
    "\n",
    "# Appends current working dir\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "\n",
    "# Import custom preprocessing class\n",
    "from imc_preprocessing import IMCPreprocessor\n",
    "\n",
    "# Import Stratified Split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d03d7d-be22-491c-915e-f9ebff1f54b1",
   "metadata": {},
   "source": [
    "#### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ede3c32-a3d7-4e01-b26a-57eb0b5b6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (if needed)\n",
    "def preprocessing(image, transpose=True, normalize=True) -> np.ndarray:\n",
    "    if transpose:\n",
    "        return np.transpose(image, (1, 2, 0))\n",
    "    if normalize:\n",
    "        return IMCPreprocessor.normalize_multichannel_image(image)\n",
    "\n",
    "# Load images\n",
    "def load_image(image_path) -> np.ndarray:\n",
    "    image = tiff.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    return image\n",
    "\n",
    "\n",
    "# Define a function to create a list of images from files within a folder \n",
    "def image_list(image_dir):\n",
    "    # List all files in the directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]  \n",
    "    # Initialize a list to store the images\n",
    "    images = []\n",
    "    # Loop through each file and read the image\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        image = load_image(image_path)\n",
    "        images.append(image)        \n",
    "    return images \n",
    "\n",
    "# Converting to one hot\n",
    "def convert_to_one_hot(y, classes):\n",
    "    return np.eye(classes)[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a5e4f-4da8-4210-ad97-02ec4857abbe",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "#### Preprocessing and Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3167372b-5c56-4c9f-a334-7fe94c2dd138",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/home/jupyter-luvogt/Final_Project_LR/IMC_images' \n",
    "metadata_dir = '/home/jupyter-luvogt/Final_Project_LR/metadata.csv' \n",
    "panel_dir = '/home/jupyter-luvogt/Final_Project_LR/panel.csv' \n",
    "os.listdir(images_dir)[:5] # Get first five images\n",
    "\n",
    "# Load images\n",
    "images = image_list(images_dir)\n",
    "images = np.array(images)\n",
    "\n",
    "# load labels\n",
    "metadata = pd.read_csv(metadata_dir)\n",
    "PDL1_score = metadata[\"PDL1_score\"]\n",
    "\n",
    "# Shape PDL1\n",
    "PDL1_score = PDL1_score.tolist()\n",
    "PDL1_score = np.array(PDL1_score)\n",
    "\n",
    "# Transpose and Normalize images\n",
    "images_preproc = [preprocessing(i, transpose = True, normalize = False) for i in images]\n",
    "images_preproc = [preprocessing(i, transpose = False, normalize = True) for i in images_preproc]\n",
    "images_preproc = np.array(images_preproc)\n",
    "\n",
    "# Extract channel information\n",
    "panel_df = pd.read_csv(panel_dir)\n",
    "channel_names = dict(zip(panel_df['clean_target'].to_list(), panel_df['channel'].to_list()))\n",
    "\n",
    "# Filter out Xe131, Xe134 and Ba138 = Noise channels (OPTIONAL) \n",
    "channel_names_new = [x for x in list(channel_names.values()) if x not in [\"Xe131\", \"Xe134\", \"Ba138\"]]\n",
    "images_preproc_drop = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "images_preproc_drop = np.array(images_preproc_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c26ff9-1878-4cd6-98e9-18d84899a49e",
   "metadata": {},
   "source": [
    "### ResNet50 Model: Trained directly here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d214a9c-5f8c-4afa-b34d-acba9c11f840",
   "metadata": {},
   "source": [
    "#### ResNet50 Model: 3 Channels & Resizing with Anti Aliasing to 64x64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7f723-8027-4f25-ad56-84c195bc2afc",
   "metadata": {},
   "source": [
    "Approach: Select biological relevant channels that correspond or are associated with PDL1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6f57187-d166-4ee9-87a2-b2822848edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 3 biological relevant channels\n",
    "channel_names_new = [\"Gd160\", \"Eu153\", \"Gd155\"]\n",
    "images_preproc_drop_3 = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "images_preproc_drop_3 = np.array(images_preproc_drop_3)\n",
    "\n",
    "channels_preproc_drop_3 = channel_names_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283d430-eb33-40ba-8ce3-af0ab813bda0",
   "metadata": {},
   "source": [
    "Create unbalanced (but with stratified) training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bcd9e35-a4f8-4292-9719-e32301151daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 56\n",
    "X = images_preproc_drop_3\n",
    "y = PDL1_score\n",
    "train_size = 0.6\n",
    "val_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "\n",
    "# Create a StratifiedShuffleSplit for train/test split\n",
    "sss_train_test = StratifiedShuffleSplit(n_splits=1, test_size=(val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# First split: Train and remaining (validation + test)\n",
    "for train_index, remaining_index in sss_train_test.split(X, y):\n",
    "    X_train, X_remaining = X[train_index], X[remaining_index]\n",
    "    y_train, y_remaining = y[train_index], y[remaining_index]\n",
    "\n",
    "# Create a StratifiedShuffleSplit for validation/test split on remaining data\n",
    "sss_val_test = StratifiedShuffleSplit(n_splits=1, test_size=test_size / (val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# Second split: Validation and Test\n",
    "for val_index, test_index in sss_val_test.split(X_remaining, y_remaining):\n",
    "    X_val, X_test = X_remaining[val_index], X_remaining[test_index]\n",
    "    y_val, y_test = y_remaining[val_index], y_remaining[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb9e96-83de-4774-802d-e8ed6390e6ce",
   "metadata": {},
   "source": [
    "Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94e3d44-f71a-47d3-8516-302c35b4d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling\n",
    "from skimage import io, transform\n",
    "X_train_64 = [transform.resize(i, (64, 64), anti_aliasing=True) for i in X_train]\n",
    "X_train_64 = np.array(X_train_64)\n",
    "X_test_64 = [transform.resize(i, (64, 64), anti_aliasing=True) for i in X_test]\n",
    "X_test_64 = np.array(X_test_64)\n",
    "X_val_64 = [transform.resize(i, (64, 64), anti_aliasing=True) for i in X_val]\n",
    "X_val_64 = np.array(X_val_64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976e1b3-9a3f-495e-b3e3-3ee076227e13",
   "metadata": {},
   "source": [
    "Define CONSTANTS and do One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c5b483e-b951-4b99-af09-a8dbab68d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "ROWS = 64\n",
    "COLS = 64\n",
    "CHANNELS = 3\n",
    "CLASSES = 2\n",
    "\n",
    "y_train_one_hot = convert_to_one_hot(y_train, CLASSES)\n",
    "y_test_one_hot = convert_to_one_hot(y_test, CLASSES)\n",
    "y_val_one_hot = convert_to_one_hot(y_val, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56165598-bc31-4817-a6bc-cf7f1d2a5804",
   "metadata": {},
   "source": [
    "Define Blocks and ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d77d4e7-e328-467e-8904-685284dbc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    # Save the input value. We'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "    \n",
    "def ResNet50(input_shape = (64, 64, 3), classes = 2):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1623e1-9fd7-4de6-941b-8d764c333cdb",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fee88-2f3f-4ec7-944b-dfb4920ff55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Network Graph \n",
    "model_ResNet50 = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet50.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 50\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet50 = model_ResNet50.fit(X_train_64, y_train_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val_64, y_val_one_hot),\n",
    "                                      callbacks=tb_callback)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afecce0-ba59-465c-9b47-88633a2ee3cc",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Observing our validation and testing accuracy, our model is performing very badly on the test set while overfitting to the training set. \n",
    "\n",
    "2 possible errors contributing to that: \n",
    "    1. Downsampling of images from 224x224 to 64x64 --> loss of information \n",
    "    2. Uninformative channels used \n",
    "\n",
    "Approaches to solve issues:\n",
    "\n",
    "    1. Problem: \n",
    "        - Just use 224x224 pixel images\n",
    "        - Use Dimensionality reduction techniques to reduce the size of the images (e.g. autoencoders)\n",
    "        \n",
    "    2. Problem: \n",
    "        - Access the most significant channels by first apply\n",
    "            a) Shallow CNNs (per channel or with all channels) and then analyzing\n",
    "                - SHAP\n",
    "            b) Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6aa7dd-750d-44b0-b57e-48dfa9f63671",
   "metadata": {},
   "source": [
    "### ResNet50: 3 Channels but without Resizing (224x224) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334075e9-7b29-42be-83bb-dc53693f1875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734124653.153374  628323 service.cc:146] XLA service 0x7fca78006230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734124653.153406  628323 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-13 21:17:33.898189: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-13 21:17:36.534641: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "2024-12-13 21:17:41.569654: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 18.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1734124677.960271  628323 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.5818 - loss: 1.0362 - val_accuracy: 0.6396 - val_loss: 0.6869\n",
      "Epoch 2/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 466ms/step - accuracy: 0.6684 - loss: 0.7175 - val_accuracy: 0.6396 - val_loss: 0.6830\n",
      "Epoch 3/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 451ms/step - accuracy: 0.8483 - loss: 0.4571 - val_accuracy: 0.6396 - val_loss: 0.6590\n",
      "Epoch 4/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 455ms/step - accuracy: 0.9640 - loss: 0.2288 - val_accuracy: 0.6396 - val_loss: 0.6554\n",
      "Epoch 5/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 456ms/step - accuracy: 0.9920 - loss: 0.1257 - val_accuracy: 0.6396 - val_loss: 0.6851\n",
      "Epoch 6/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 465ms/step - accuracy: 0.9891 - loss: 0.1053 - val_accuracy: 0.6396 - val_loss: 0.7335\n",
      "Epoch 7/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 468ms/step - accuracy: 0.9987 - loss: 0.0406 - val_accuracy: 0.6396 - val_loss: 0.7902\n",
      "Epoch 8/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 463ms/step - accuracy: 0.9964 - loss: 0.0244 - val_accuracy: 0.6396 - val_loss: 1.0295\n",
      "Epoch 9/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 461ms/step - accuracy: 0.9923 - loss: 0.0412 - val_accuracy: 0.6396 - val_loss: 1.0708\n",
      "Epoch 10/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 462ms/step - accuracy: 0.9969 - loss: 0.0283 - val_accuracy: 0.6396 - val_loss: 1.4190\n",
      "Epoch 11/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 458ms/step - accuracy: 0.9911 - loss: 0.0368 - val_accuracy: 0.6396 - val_loss: 1.2059\n",
      "Epoch 12/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 456ms/step - accuracy: 0.9952 - loss: 0.0322 - val_accuracy: 0.6396 - val_loss: 1.0484\n",
      "Epoch 13/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 457ms/step - accuracy: 0.9885 - loss: 0.0566 - val_accuracy: 0.6142 - val_loss: 0.6752\n",
      "Epoch 14/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 453ms/step - accuracy: 0.9823 - loss: 0.0469 - val_accuracy: 0.6396 - val_loss: 1.0335\n",
      "Epoch 15/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 467ms/step - accuracy: 0.9807 - loss: 0.0510 - val_accuracy: 0.6345 - val_loss: 0.7398\n",
      "Epoch 16/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 463ms/step - accuracy: 0.9828 - loss: 0.0797 - val_accuracy: 0.6345 - val_loss: 0.7701\n",
      "Epoch 17/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 461ms/step - accuracy: 0.9385 - loss: 0.2071 - val_accuracy: 0.6599 - val_loss: 0.8671\n",
      "Epoch 18/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 462ms/step - accuracy: 0.9517 - loss: 0.1299 - val_accuracy: 0.6396 - val_loss: 1.7600\n",
      "Epoch 19/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 460ms/step - accuracy: 0.9506 - loss: 0.2209 - val_accuracy: 0.6396 - val_loss: 1.3216\n",
      "Epoch 20/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 463ms/step - accuracy: 0.9640 - loss: 0.1728 - val_accuracy: 0.6447 - val_loss: 1.1909\n",
      "\n",
      "Elapsed time: 249.89197039604187 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build Network Graph \n",
    "# Take original Size\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 3\n",
    "model_ResNet50 = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet50.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 32\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet50 = model_ResNet50.fit(X_train, y_train_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val_one_hot),\n",
    "                                      callbacks=tb_callback)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9282d59-e798-48bd-91f5-00716437bffa",
   "metadata": {},
   "source": [
    "#### COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e069d7-3bfb-466a-8aff-d31e49ac7a6e",
   "metadata": {},
   "source": [
    "Observing our validation and testing accuracy, our model is still performing very badly on the validation set while overfitting to the training set, even with 224x224 pixels a\n",
    "INTERESTING: validation accuracy constantly 0.6396 indicates that model only predicts PDL1 == 0 as this is the distribution in our unbalanced validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab3178e-971d-4d91-b2fd-24b8cd244358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6493 - loss: 1.2322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3231925964355469, 0.624365508556366]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ResNet50.evaluate(X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dab2d3-d6cc-4db9-8eae-215eb2cd510f",
   "metadata": {},
   "source": [
    "### ResNet50: 10 Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9dba58-aed9-45c6-b56b-3d1b50366027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 3 biological relevant channels\n",
    "channel_names_new = [\"Gd160\", \"Eu153\", \"Gd155\", \"Er166\", \"Er170\", \"Nd146\", \"Yb173\", \"Nd145\", \"Tb159\", \"Yb171\"]\n",
    "images_preproc_drop_10 = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "images_preproc_drop_10 = np.array(images_preproc_drop_10)\n",
    "random_seed = 56\n",
    "X = images_preproc_drop_10\n",
    "y = PDL1_score\n",
    "train_size = 0.6\n",
    "val_size = 0.2\n",
    "test_size = 0.2\n",
    "# Create a StratifiedShuffleSplit for train/test split\n",
    "sss_train_test = StratifiedShuffleSplit(n_splits=1, test_size=(val_size + test_size), random_state=random_seed)\n",
    "# First split: Train and remaining (validation + test)\n",
    "for train_index, remaining_index in sss_train_test.split(X, y):\n",
    "    X_train, X_remaining = X[train_index], X[remaining_index]\n",
    "    y_train, y_remaining = y[train_index], y[remaining_index]\n",
    "# Create a StratifiedShuffleSplit for validation/test split on remaining data\n",
    "sss_val_test = StratifiedShuffleSplit(n_splits=1, test_size=test_size / (val_size + test_size), random_state=random_seed)\n",
    "# Second split: Validation and Test\n",
    "for val_index, test_index in sss_val_test.split(X_remaining, y_remaining):\n",
    "    X_val, X_test = X_remaining[val_index], X_remaining[test_index]\n",
    "    y_val, y_test = y_remaining[val_index], y_remaining[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87d252d4-a414-485d-9a41-d451035ebabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.5478 - loss: 1.1325 - val_accuracy: 0.3604 - val_loss: 0.6978\n",
      "Epoch 2/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.7582 - loss: 0.6312 - val_accuracy: 0.6396 - val_loss: 0.6770\n",
      "Epoch 3/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 481ms/step - accuracy: 0.8441 - loss: 0.4376 - val_accuracy: 0.6396 - val_loss: 0.6677\n",
      "Epoch 4/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 466ms/step - accuracy: 0.9331 - loss: 0.2697 - val_accuracy: 0.6396 - val_loss: 0.6628\n",
      "Epoch 5/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 472ms/step - accuracy: 0.9889 - loss: 0.1432 - val_accuracy: 0.6396 - val_loss: 0.6589\n",
      "Epoch 6/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 484ms/step - accuracy: 0.9902 - loss: 0.1118 - val_accuracy: 0.6396 - val_loss: 0.6570\n",
      "Epoch 7/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 489ms/step - accuracy: 0.9884 - loss: 0.0827 - val_accuracy: 0.6396 - val_loss: 0.8307\n",
      "Epoch 8/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 473ms/step - accuracy: 0.9952 - loss: 0.0282 - val_accuracy: 0.6396 - val_loss: 0.7799\n",
      "Epoch 9/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.6396 - val_loss: 0.7246\n",
      "Epoch 10/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.6396 - val_loss: 0.8391\n",
      "Epoch 11/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.6396 - val_loss: 1.1021\n",
      "Epoch 12/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.6396 - val_loss: 1.1573\n",
      "Epoch 13/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6396 - val_loss: 1.1606\n",
      "Epoch 14/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 484ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.5228 - val_loss: 0.7245\n",
      "Epoch 15/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.6396 - val_loss: 1.0645\n",
      "Epoch 16/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.6244 - val_loss: 0.8260\n",
      "Epoch 17/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 488ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.6142 - val_loss: 0.9074\n",
      "Epoch 18/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 489ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.6345 - val_loss: 0.9869\n",
      "Epoch 19/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 486ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6294 - val_loss: 1.3393\n",
      "Epoch 20/20\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 490ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6193 - val_loss: 1.0812\n",
      "\n",
      "Elapsed time: 254.60124850273132 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224\n",
    "COLS = 224\n",
    "# Change Channels to 10\n",
    "CHANNELS = 10\n",
    "model_ResNet50 = ResNet50(input_shape = (ROWS, COLS, CHANNELS), classes = CLASSES)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet50.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Apply TensorBoard\n",
    "# define the logs folder \n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# Define TensorBoard Callback\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 32\n",
    "epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet50 = model_ResNet50.fit(X_train, y_train_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val_one_hot),\n",
    "                                      callbacks=tb_callback)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0adc4e-aa31-456f-a91e-3f99bc4484c0",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "Increasing Channels did not help the overfitting problem: validation accuracy still stagnates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74adcd9f-b76d-40e0-920c-454386521128",
   "metadata": {},
   "source": [
    "### ResNet50: 3 Channels + Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dec6ca-3796-40b7-a812-858fc4c669e3",
   "metadata": {},
   "source": [
    "Redefine ResNet50 with L2 Regularizers for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8bd0d34-684c-4f6e-bf81-212ed3afbdbc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "def identity_block(X, f, filters, stage, block, l2_lambda = 0.01):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    # Save the input value. We'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "def convolutional_block(X, f, filters, stage, block, l2_lambda = 0.01, s = 2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "    \n",
    "def ResNet50(input_shape = (64, 64, 3), l2_lambda = 0.01, classes = 2):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1, l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b', l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c', l2_lambda=l2_lambda)\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2, l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b', l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c', l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d', l2_lambda=l2_lambda)\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2, l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b', l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c', l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d', l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e', l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f', l2_lambda=l2_lambda)\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2, l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b', l2_lambda=l2_lambda)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c', l2_lambda=l2_lambda)\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "083b449f-00d4-4045-b551-7efdb959f36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.5571 - loss: 1774.6960 - val_accuracy: 0.6396 - val_loss: 1665.2546\n",
      "Epoch 2/5\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 269ms/step - accuracy: 0.7156 - loss: 1630.5818 - val_accuracy: 0.6396 - val_loss: 1527.1132\n",
      "Epoch 3/5\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 271ms/step - accuracy: 0.8277 - loss: 1494.3605 - val_accuracy: 0.6396 - val_loss: 1398.1536\n",
      "Epoch 4/5\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 274ms/step - accuracy: 0.8814 - loss: 1367.8191 - val_accuracy: 0.6396 - val_loss: 1279.4423\n",
      "Epoch 5/5\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 276ms/step - accuracy: 0.9112 - loss: 1251.5955 - val_accuracy: 0.6396 - val_loss: 1171.0596\n",
      "\n",
      "Elapsed time: 100.53303241729736 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build Network Graph \n",
    "# Take original Size\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 3\n",
    "l2_lambda = 0.1\n",
    "model_ResNet50 = ResNet50(input_shape = (ROWS, COLS, CHANNELS), l2_lambda=l2_lambda, classes = CLASSES)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet50.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Apply TensorBoard\n",
    "# # define the logs folder \n",
    "# log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # Define TensorBoard Callback\n",
    "# tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 32\n",
    "epochs = 5\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet50 = model_ResNet50.fit(X_train, y_train_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val_one_hot))\n",
    "                                      \n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e298a4-bf76-4f9d-80af-9241919d1428",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Problem is still present even with regularization\n",
    "\n",
    "Maybe increase l2_lambda?: doesn't help either (additional step modified in code above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0c4d0-b6ec-4a3d-b7a9-11bc8078f30d",
   "metadata": {},
   "source": [
    "### ResNet50: 3 Channels + Regularization + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae21059-e124-498c-ada0-b9eb6b1992cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "def identity_block(X, f, filters, stage, block, l2_lambda = 0.01, dropout = 0.2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    # Save the input value. We'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Dropout(dropout)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Dropout(dropout)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "def convolutional_block(X, f, filters, stage, block, l2_lambda = 0.01, s = 2, dropout = 0.2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Dropout(dropout)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Dropout(dropout)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    return X\n",
    "    \n",
    "def ResNet50(input_shape = (64, 64, 3), l2_lambda = 0.01, classes = 2, dropout = 0.2):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Dropout(dropout)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1, l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2, l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2, l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2, l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c', l2_lambda=l2_lambda, dropout = dropout)\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0), kernel_regularizer = l2(l2_lambda))(X)\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f353a70-54a4-4a1e-9932-05aba7539b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 3 biological relevant channels\n",
    "channel_names_new = [\"Gd160\", \"Eu153\", \"Gd155\"]\n",
    "images_preproc_drop_3 = [IMCPreprocessor.drop_channels(i, channel_names_new, list(channel_names.values()))[0] for i in images_preproc]\n",
    "images_preproc_drop_3 = np.array(images_preproc_drop_3)\n",
    "\n",
    "random_seed = 56\n",
    "X = images_preproc_drop_3\n",
    "y = PDL1_score\n",
    "train_size = 0.6\n",
    "val_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "\n",
    "# Create a StratifiedShuffleSplit for train/test split\n",
    "sss_train_test = StratifiedShuffleSplit(n_splits=1, test_size=(val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# First split: Train and remaining (validation + test)\n",
    "for train_index, remaining_index in sss_train_test.split(X, y):\n",
    "    X_train, X_remaining = X[train_index], X[remaining_index]\n",
    "    y_train, y_remaining = y[train_index], y[remaining_index]\n",
    "\n",
    "# Create a StratifiedShuffleSplit for validation/test split on remaining data\n",
    "sss_val_test = StratifiedShuffleSplit(n_splits=1, test_size=test_size / (val_size + test_size), random_state=random_seed)\n",
    "\n",
    "# Second split: Validation and Test\n",
    "for val_index, test_index in sss_val_test.split(X_remaining, y_remaining):\n",
    "    X_val, X_test = X_remaining[val_index], X_remaining[test_index]\n",
    "    y_val, y_test = y_remaining[val_index], y_remaining[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34680704-2a57-4468-8f63-57daac3135d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3s/step - accuracy: 0.5618 - loss: 1771.9072 - val_accuracy: 0.6396 - val_loss: 1655.6842\n",
      "Epoch 2/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 278ms/step - accuracy: 0.5822 - loss: 1620.0887 - val_accuracy: 0.6396 - val_loss: 1514.1362\n",
      "Epoch 3/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 280ms/step - accuracy: 0.6292 - loss: 1481.4170 - val_accuracy: 0.3604 - val_loss: 1384.4082\n",
      "Epoch 4/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 281ms/step - accuracy: 0.5329 - loss: 1354.5082 - val_accuracy: 0.6497 - val_loss: 1265.9998\n",
      "Epoch 5/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.6252 - loss: 1238.7194 - val_accuracy: 0.6396 - val_loss: 1158.1440\n",
      "Epoch 6/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.5929 - loss: 1133.5695 - val_accuracy: 0.6396 - val_loss: 1060.2393\n",
      "Epoch 7/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.6494 - loss: 1037.6554 - val_accuracy: 0.3604 - val_loss: 970.8281\n",
      "Epoch 8/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.6555 - loss: 950.1215 - val_accuracy: 0.6396 - val_loss: 889.0999\n",
      "Epoch 9/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 294ms/step - accuracy: 0.6236 - loss: 870.4034 - val_accuracy: 0.6396 - val_loss: 814.8469\n",
      "Epoch 10/10\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 296ms/step - accuracy: 0.5908 - loss: 798.2966 - val_accuracy: 0.6396 - val_loss: 747.2563\n",
      "\n",
      "Elapsed time: 218.55874300003052 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build Network Graph \n",
    "# Take original Size\n",
    "ROWS = 224\n",
    "COLS = 224\n",
    "CHANNELS = 3\n",
    "CLASSES = 2\n",
    "l2_lambda = 0.1\n",
    "dropout = 0.2\n",
    "model_ResNet50 = ResNet50(input_shape = (ROWS, COLS, CHANNELS), l2_lambda=l2_lambda, classes = CLASSES, dropout = dropout)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "\n",
    "model_ResNet50.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Apply TensorBoard\n",
    "# # define the logs folder \n",
    "# log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet50_3Channels\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# # Define TensorBoard Callback\n",
    "# tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train Model \n",
    "batch = 32\n",
    "epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet50 = model_ResNet50.fit(X_train, y_train_one_hot, \n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val_one_hot))\n",
    "                                      \n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59779fe0-2ebe-425f-8b2e-f2cd187a759d",
   "metadata": {},
   "source": [
    "#### COMMENTS\n",
    "\n",
    "Problem of stagnating validation accuracy still persists even with drop out. Validation accuracy constantly 0.6396 or 0.3604 (with some exceptions...) --> only predicting one or the other class\n",
    "\n",
    "Also: with Dropout models fails to overfit on the training set, while with regularization it overvits \n",
    "\n",
    "Approaches from here: \n",
    "\n",
    "    - ResNet18: Apply less complex model\n",
    "    - Dimensionality Reduction: Autoencoders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BME342 Env",
   "language": "python",
   "name": "bme342_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
