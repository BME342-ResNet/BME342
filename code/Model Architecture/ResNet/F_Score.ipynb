{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6423c422-04da-4edb-ba56-2a146476f0ba",
   "metadata": {},
   "source": [
    "# ResNet: Tensorflow Train\n",
    "\n",
    "Because we train our model with an unbalanced dataset, it's recommended to use F1 Score as the metric to assess our models quality. \n",
    "\n",
    "With this in mind, we will re-train our ResNet18 using F1 Score instead of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d287ef90-f246-452c-82a0-9d04df91e2d6",
   "metadata": {},
   "source": [
    "### Initialize Notebook & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540f84f3-10a2-4635-b20c-3fd5939db3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-18 23:40:12.467778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-18 23:40:12.482128: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-18 23:40:12.486573: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-18 23:40:12.497549: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU enabled. Checking for available GPUs...\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "\n",
      "Verifying TensorFlow and PyTorch CUDA setup...\n",
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: True\n",
      "Num GPUs Available: 1\n",
      "\n",
      "Keras version: 3.6.0\n",
      "\n",
      "End checks and initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734565214.449484  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734565214.488722  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734565214.492185  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734565214.497363  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734565214.500683  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734565214.503901  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734565214.692443  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734565214.694255  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734565214.695900  878837 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-18 23:40:14.697499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13312 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import helper as hp \n",
    "hp.initialize_notebook() # initialize with GPU enabled  \n",
    "# hp.initialize_notebook(False) # to disable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a539d5b-87bd-4bef-9dce-e8ed23101a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import keras\n",
    "# Import DL libraries\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout # General Layers\n",
    "from keras.layers import RandomRotation, RandomFlip\n",
    "from keras import layers, models, Model, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import F1Score, AUC\n",
    "# Suppress tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import ML libraries\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Import image libraries\n",
    "from skimage import transform\n",
    "import tifffile as tiff\n",
    "from tifffile import imread\n",
    "\n",
    "# Appends current working dir\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "\n",
    "# Import custom preprocessing class\n",
    "from imc_preprocessing import IMCPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae5700-11b4-45a2-8685-0f902de0fe82",
   "metadata": {},
   "source": [
    "### Clear GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d5b5a3-ffb8-4aa6-a104-007089a21c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# Clear TensorFlow session and reset the graph\n",
    "K.clear_session()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b81817-ac05-4c27-9a08-c4358a629c1b",
   "metadata": {},
   "source": [
    "## IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b0bc5-7e74-41b4-a06f-35ada36a27fc",
   "metadata": {},
   "source": [
    "### Train, validation and test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5405b3-fab2-4569-8522-f7b2c02a69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '../../../IMC_images' \n",
    "metadata_dir = '../../../metadata.csv'\n",
    "# --- Load CSV and filter dataset ---\n",
    "csv_file = metadata_dir\n",
    "image_folder = images_dir\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Filter rows with NA in PDL1_score and convert to binary\n",
    "df = df.dropna(subset=[\"PDL1_score\"])\n",
    "df[\"PDL1_score\"] = df[\"PDL1_score\"].astype(int)\n",
    "\n",
    "# --- Train-Test-Validation Split ---\n",
    "train_df, val_and_test_df = train_test_split(df, test_size=0.4, random_state=42, stratify=df[\"PDL1_score\"])\n",
    "test_df, val_df = train_test_split(val_and_test_df, test_size=0.5, random_state=42, stratify=val_and_test_df[\"PDL1_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebbbc41-02aa-43bb-b875-552d15b12834",
   "metadata": {},
   "source": [
    "### Import function for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f060b1f-09d4-4828-b6c6-06305c1d984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load Images and Compute Mean and Standard Deviation ---\n",
    "# Function to load a single image\n",
    "def load_image(image_path):\n",
    "    image = imread(image_path)  # Load all 46 channels\n",
    "    return image.astype(np.float32)\n",
    "\n",
    "# Initialize variables to accumulate sum and sum of squares\n",
    "nr_images = 0\n",
    "sum_images = np.zeros((46, 224, 224))\n",
    "sum_squared_images = np.zeros((46, 224, 224))\n",
    "\n",
    "# Accumulate the sum and sum of squares for the training dataset\n",
    "for _, row in train_df.iterrows():\n",
    "    image_path = os.path.join(image_folder, f\"{row['sample_id']}.tiff\")\n",
    "    image = load_image(image_path)\n",
    "    nr_images += 1\n",
    "    sum_images += image\n",
    "    sum_squared_images += image ** 2\n",
    "\n",
    "# Compute mean and standard deviation\n",
    "mean = sum_images / nr_images\n",
    "std = np.sqrt(sum_squared_images / nr_images - mean ** 2)\n",
    "\n",
    "# --- Dataset Loading Function ---\n",
    "\n",
    "def load_dataset(dataframe, image_folder, normalize = True): # augment = False\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in dataframe.iterrows():\n",
    "        image_path = os.path.join(image_folder, f\"{row['sample_id']}.tiff\")\n",
    "        image = load_image(image_path)\n",
    "\n",
    "        if normalize:\n",
    "            image = (image - mean) / std # Z-Score\n",
    "\n",
    "        # Convert to channels-last format (224, 224, 46)\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "        # # Apply data augmentation if specified\n",
    "        # if augment:\n",
    "        #     # Random horizontal flip\n",
    "        #     if np.random.rand() > 0.5:\n",
    "        #         image = np.flip(image, axis=2)\n",
    "        #     # Random vertical flip\n",
    "        #     if np.random.rand() > 0.5:\n",
    "        #         image = np.flip(image, axis=1)\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(row[\"PDL1_score\"])\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfaf9f-8ab2-4b85-b576-fe70bbb53ffc",
   "metadata": {},
   "source": [
    "## ResNet18: with Tensor Board + 46 Channels + with Dropout + ReduceLR + EarlyStopping + sigmoid instead of softmax + 1 neuron instead of "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db913bb-2abf-4c3a-aa86-523e2f5390f7",
   "metadata": {},
   "source": [
    "Adjust the last classificaiton layer to contain 1 neuron and the sigmoid activation function (instead of 2 neurons and the softmax), because this is more suited for binary classificaiton. Model retrained underneath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993d258-5cfe-4b4d-8e6a-4d484243aa18",
   "metadata": {},
   "source": [
    "### Create Datasets: Disable one-hot encoding for sigmoid / F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8101ec-37e6-40e5-9463-00f60c31e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (590, 224, 224, 46), y_train shape: (590,)\n",
      "X_val shape: (197, 224, 224, 46), y_val shape: (197,)\n",
      "X_test shape: (197, 224, 224, 46), y_test shape: (197,)\n"
     ]
    }
   ],
   "source": [
    "# Training dataset without augmentation\n",
    "X_train, y_train = load_dataset(train_df, image_folder, normalize = True)\n",
    "# # Training dataset with data augmentation\n",
    "# X_train_aug, y_train_aug = load_dataset(train_df, image_folder, augment=True)\n",
    "# Validation dataset\n",
    "X_val, y_val = load_dataset(val_df, image_folder, normalize = True)\n",
    "# Test dataset\n",
    "X_test, y_test = load_dataset(test_df, image_folder, normalize = True)\n",
    "\n",
    "# #  Disable for F1_score / Sigmoid \n",
    "# # One Hot Encoding\n",
    "# y_train= to_categorical(y_train)\n",
    "# y_val= to_categorical(y_val)\n",
    "# y_test = to_categorical(y_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bfb016-edd4-468f-9107-b9f3b1bcbbb4",
   "metadata": {},
   "source": [
    "### ResNet18: with Tensor Board + 46 Channels + with Dropout + ReduceLR + EarlyStopping + sigmoid (1 neuron) + binary cross entropy\n",
    "\n",
    "Redefine Model Architecture\n",
    "\n",
    "Classification layer: 1 neuron + simgoid activation function (not one-hot encoded labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b46899-0938-4817-bb2d-c6771a086e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3], dropout_rate = 0.5):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation = 'sigmoid')(x) # Change last layer here: sigmoid and 1 neuron (classes -1)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet18\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f2069-52eb-4f95-b038-5e2fbbc75f40",
   "metadata": {},
   "source": [
    "### Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613392c7-5ea6-4641-85f2-de0172872332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_callbacks_sigmoid_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet18_46_dropout_callbacks_sigmoid_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b74064-c987-475d-9c91-23c09fd358d1",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a43deb3-3a42-41b7-a801-942b7a8559d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 20:31:58.954632: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-17 20:32:01.576083: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.5334 - loss: 1.9368 - val_accuracy: 0.4061 - val_loss: 0.9245 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 639ms/step - accuracy: 0.6127 - loss: 1.0147 - val_accuracy: 0.3756 - val_loss: 1.1592 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 614ms/step - accuracy: 0.6215 - loss: 0.6876 - val_accuracy: 0.4873 - val_loss: 0.9402 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 756ms/step - accuracy: 0.6769 - loss: 0.6390 - val_accuracy: 0.6599 - val_loss: 0.7409 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 600ms/step - accuracy: 0.7233 - loss: 0.6002 - val_accuracy: 0.6345 - val_loss: 0.7785 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 744ms/step - accuracy: 0.7419 - loss: 0.5228 - val_accuracy: 0.7462 - val_loss: 0.5937 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 747ms/step - accuracy: 0.8292 - loss: 0.4202 - val_accuracy: 0.7614 - val_loss: 0.5408 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 731ms/step - accuracy: 0.8342 - loss: 0.3805 - val_accuracy: 0.7868 - val_loss: 0.4945 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 717ms/step - accuracy: 0.8384 - loss: 0.4031 - val_accuracy: 0.7868 - val_loss: 0.4847 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 749ms/step - accuracy: 0.8599 - loss: 0.3373 - val_accuracy: 0.8122 - val_loss: 0.4811 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 596ms/step - accuracy: 0.8686 - loss: 0.2924 - val_accuracy: 0.7919 - val_loss: 0.5469 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 769ms/step - accuracy: 0.8668 - loss: 0.2926 - val_accuracy: 0.8223 - val_loss: 0.4342 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 739ms/step - accuracy: 0.8913 - loss: 0.2789 - val_accuracy: 0.8020 - val_loss: 0.4340 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 641ms/step - accuracy: 0.8696 - loss: 0.3069 - val_accuracy: 0.8376 - val_loss: 0.4429 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8976 - loss: 0.2679\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 606ms/step - accuracy: 0.8980 - loss: 0.2665 - val_accuracy: 0.8020 - val_loss: 0.5054 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 608ms/step - accuracy: 0.8928 - loss: 0.2623 - val_accuracy: 0.8376 - val_loss: 0.4384 - learning_rate: 5.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 735ms/step - accuracy: 0.8927 - loss: 0.2625 - val_accuracy: 0.8325 - val_loss: 0.3829 - learning_rate: 5.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 616ms/step - accuracy: 0.9098 - loss: 0.2363 - val_accuracy: 0.8122 - val_loss: 0.4090 - learning_rate: 5.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 584ms/step - accuracy: 0.9037 - loss: 0.2153 - val_accuracy: 0.8173 - val_loss: 0.4066 - learning_rate: 5.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.8970 - loss: 0.2329\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 599ms/step - accuracy: 0.8970 - loss: 0.2348 - val_accuracy: 0.8325 - val_loss: 0.4024 - learning_rate: 5.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 735ms/step - accuracy: 0.8803 - loss: 0.2598 - val_accuracy: 0.8274 - val_loss: 0.3775 - learning_rate: 2.5000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 627ms/step - accuracy: 0.9034 - loss: 0.2407 - val_accuracy: 0.8274 - val_loss: 0.4465 - learning_rate: 2.5000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 607ms/step - accuracy: 0.9100 - loss: 0.2223 - val_accuracy: 0.8274 - val_loss: 0.4231 - learning_rate: 2.5000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.9181 - loss: 0.2128\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 599ms/step - accuracy: 0.9172 - loss: 0.2142 - val_accuracy: 0.8426 - val_loss: 0.3788 - learning_rate: 2.5000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 640ms/step - accuracy: 0.9036 - loss: 0.2164 - val_accuracy: 0.8223 - val_loss: 0.3950 - learning_rate: 1.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 623ms/step - accuracy: 0.9081 - loss: 0.2400 - val_accuracy: 0.8223 - val_loss: 0.4260 - learning_rate: 1.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.9006 - loss: 0.2353\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 611ms/step - accuracy: 0.9004 - loss: 0.2350 - val_accuracy: 0.8223 - val_loss: 0.4142 - learning_rate: 1.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 617ms/step - accuracy: 0.9019 - loss: 0.2016 - val_accuracy: 0.8223 - val_loss: 0.4101 - learning_rate: 6.2500e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 625ms/step - accuracy: 0.9075 - loss: 0.2187 - val_accuracy: 0.8223 - val_loss: 0.4157 - learning_rate: 6.2500e-06\n",
      "\n",
      "Elapsed time: 255.0923137664795 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224; COLS = 224; CHANNELS = 46; CLASSES = 2; block_layers = [2,2,2,2] # ResNet18\n",
    "dropout_rate = 0.5\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "model_ResNet18.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"accuracy\"]) # Set threshold here\n",
    "\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 50\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787f0048-24a3-4ad9-9da4-eea881800c07",
   "metadata": {},
   "source": [
    "### Testing Accuracy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dfb078d-18b8-42a7-910d-1a37feb0cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734469627.928147  737432 service.cc:146] XLA service 0x7f657401c980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734469627.928187  737432 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-17 21:07:07.960063: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-17 21:07:08.109836: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 5s/step - accuracy: 0.7812 - loss: 0.8101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734469631.167003  737432 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - accuracy: 0.8090 - loss: 0.5734\n",
      "Test Accuracy is: 0.81%\n"
     ]
    }
   ],
   "source": [
    "# To load the model from file uncomment and run the following \n",
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_callbacks_sigmoid_trained.keras')\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499da9e-c437-4899-b202-f904f0b51303",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698f6f69-e833-4c43-bbba-177584908ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred_test = loaded_model.predict(X_test)\n",
    "y_pred_test = (y_pred_test > 0.5).astype(int)\n",
    "f1 = f1_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c50b18c-b000-4aa0-af48-1335396888fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score is: 70.87%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-Score is: {:.2f}%\".format(f1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c7934e-2dd6-47e3-8d86-e6ef0d89483b",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f889bb-03f3-40ee-95aa-4ed8a7403fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_callbacks_sigmoid_trained.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab397fee-f493-4e94-8e86-7b4a6660dc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734474643.525333  743389 service.cc:146] XLA service 0x7fce7d01d050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734474643.525374  743389 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-17 22:30:43.617004: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-17 22:30:43.830169: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/7\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734474647.341526  743389 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 362ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_callbacks_sigmoid_trained.keras')\n",
    "y_pred_test = loaded_model.predict(X_test)\n",
    "y_pred_test = (y_pred_test > 0.5).astype(int)\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Add class labels to axes\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Add text annotations for each cell\n",
    "    thresh = cm.max() / 2  # Threshold for text color\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# # Example confusion matrix (computed earlier or loaded)\n",
    "# cm_ex = np.array([\n",
    "#     [50, 2, 1],\n",
    "#     [5, 45, 3],\n",
    "#     [2, 6, 40]\n",
    "# ])\n",
    "\n",
    "# Class names (optional, for labeling the axes)\n",
    "class_names = ['PDL1 == 0', 'PDL1 == 1']\n",
    "\n",
    "# Call the function to plot the confusion matrix\n",
    "plot_confusion_matrix(cm, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd143cf-38b9-44da-ad78-d28f39e7fa65",
   "metadata": {},
   "source": [
    "## ResNet18: with Tensor Board + 46 Channels + with Dropout + ReduceLR + EarlyStopping + softmax + categorical cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f191f-050b-4673-9fb7-30153358b2e4",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1607308-8720-4c4a-9de8-4f29f537ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "log_dir = os.path.join(\"logs_ResNet50\", \"fit\", \"model_ResNet18_46_dropout_callbacks_f1_score_trained\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=8,   # Optimal patience value for validation accuracy\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models_ResNet/model_ResNet18_46_dropout_callbacks_f1_score_trained.keras\", # save validation loss into file\n",
    "        monitor=\"val_loss\",  # monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  \n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    min_lr=1.e-6,\n",
    "    ), \n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31059e-d123-4032-8e1c-83286d5c8aca",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd22828-a61a-40ef-8182-b28dd520066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Disable for F1_score / Sigmoid \n",
    "# One Hot Encoding\n",
    "y_train= to_categorical(y_train)\n",
    "y_val= to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898b7fd-94c5-4a09-9631-c96b32a70fe3",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82ab9bab-f565-4dce-afdc-97e0d6a19fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, filter, dropout_rate = 0.5):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def ResNet(shape = (32, 32, 3), classes = 10, block_layers = [3, 4, 6, 3], dropout_rate = 0.5):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = block_layers\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = tf.keras.layers.Dense(2, activation = 'softmax')(x) # CHANGE HERE\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet18\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260b88f-ad0f-4194-88d4-b72e8b7bd48a",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e5193-348e-4e0d-b5c4-88cd82d6bba8",
   "metadata": {},
   "source": [
    "Change loss: \n",
    "\n",
    "    - categorical cross_entropy for softmax\n",
    "    - binary cross_entropy for sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de032e2a-ba0d-4047-93d1-eea70d3d78a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 20:27:11.512423: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n",
      "2024-12-17 20:27:14.123282: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5447106560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734467245.857384  731931 service.cc:146] XLA service 0x7f4114004230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734467245.857439  731931 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-12-17 20:27:26.115019: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-17 20:27:27.094336: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n",
      "2024-12-17 20:27:30.525386: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1734467270.441060  731931 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.5658 - loss: 1.8393 - val_accuracy: 0.3655 - val_loss: 3.6623 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 809ms/step - accuracy: 0.6499 - loss: 1.1858 - val_accuracy: 0.3756 - val_loss: 2.4612 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 771ms/step - accuracy: 0.6730 - loss: 0.7471 - val_accuracy: 0.4010 - val_loss: 1.9207 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 744ms/step - accuracy: 0.6889 - loss: 0.7233 - val_accuracy: 0.5431 - val_loss: 0.9687 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 741ms/step - accuracy: 0.7400 - loss: 0.5873 - val_accuracy: 0.6548 - val_loss: 0.7549 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 737ms/step - accuracy: 0.7432 - loss: 0.5319 - val_accuracy: 0.6802 - val_loss: 0.6806 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 599ms/step - accuracy: 0.8311 - loss: 0.4120 - val_accuracy: 0.6701 - val_loss: 0.8475 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 752ms/step - accuracy: 0.8331 - loss: 0.3975 - val_accuracy: 0.7716 - val_loss: 0.5804 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 596ms/step - accuracy: 0.8326 - loss: 0.3855 - val_accuracy: 0.7868 - val_loss: 0.5899 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 610ms/step - accuracy: 0.8423 - loss: 0.3663 - val_accuracy: 0.7970 - val_loss: 0.6024 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 745ms/step - accuracy: 0.8360 - loss: 0.3437 - val_accuracy: 0.7970 - val_loss: 0.5462 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 779ms/step - accuracy: 0.8648 - loss: 0.3224 - val_accuracy: 0.7970 - val_loss: 0.5069 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 717ms/step - accuracy: 0.8684 - loss: 0.3293 - val_accuracy: 0.8071 - val_loss: 0.4699 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 760ms/step - accuracy: 0.8966 - loss: 0.2831 - val_accuracy: 0.8122 - val_loss: 0.4624 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 618ms/step - accuracy: 0.8934 - loss: 0.2900 - val_accuracy: 0.8173 - val_loss: 0.5013 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 584ms/step - accuracy: 0.8765 - loss: 0.2913 - val_accuracy: 0.8122 - val_loss: 0.4971 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.8943 - loss: 0.2705\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 612ms/step - accuracy: 0.8939 - loss: 0.2720 - val_accuracy: 0.8173 - val_loss: 0.4925 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 607ms/step - accuracy: 0.8907 - loss: 0.2701 - val_accuracy: 0.8223 - val_loss: 0.4818 - learning_rate: 5.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 621ms/step - accuracy: 0.8935 - loss: 0.2755 - val_accuracy: 0.7970 - val_loss: 0.5352 - learning_rate: 5.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.8995 - loss: 0.2421\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 621ms/step - accuracy: 0.8997 - loss: 0.2437 - val_accuracy: 0.8173 - val_loss: 0.5134 - learning_rate: 5.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 610ms/step - accuracy: 0.8930 - loss: 0.2835 - val_accuracy: 0.8223 - val_loss: 0.4966 - learning_rate: 2.5000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 607ms/step - accuracy: 0.9139 - loss: 0.2399 - val_accuracy: 0.8122 - val_loss: 0.4972 - learning_rate: 2.5000e-05\n",
      "\n",
      "Elapsed time: 223.00203800201416 seconds\n"
     ]
    }
   ],
   "source": [
    "ROWS = 224; COLS = 224; CHANNELS = 46; CLASSES = 2; block_layers = [2,2,2,2] # ResNet18\n",
    "dropout_rate = 0.5\n",
    "# Build Network Graph \n",
    "model_ResNet18 = ResNet(shape = (ROWS, COLS, CHANNELS), classes = CLASSES, block_layers = block_layers, dropout_rate = dropout_rate)\n",
    "\n",
    "# Compile Model \n",
    "l_rate = 1.e-4\n",
    "opt = keras.optimizers.Adam(learning_rate=l_rate)\n",
    "model_ResNet18.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"]) # Set threshold here\n",
    "# [F1Score(threshold = 0.5, name = \"f1_score\")]\n",
    "# Train Model \n",
    "batch = 64\n",
    "epochs = 50\n",
    "start_time = time.time()\n",
    "\n",
    "history_ResNet18 = model_ResNet18.fit(X_train, y_train,\n",
    "                                      epochs = epochs, batch_size = batch, \n",
    "                                      validation_data = (X_val, y_val), callbacks = callbacks_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nElapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000714dc-8529-4c05-90c7-36a7956b01b7",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1139bfb3-0523-4f9a-92f3-c12833039dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step - accuracy: 0.7913 - loss: 0.6654\n",
      "Test Accuracy is: 0.79%\n"
     ]
    }
   ],
   "source": [
    "# To load the model from file uncomment and run the following \n",
    "loaded_model = keras.saving.load_model('./models_ResNet/model_ResNet18_46_dropout_callbacks_f1_score_trained.keras')\n",
    "print(\"Test Accuracy is: {:.2f}%\".format(loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b344a-72e7-437e-9cc5-ca74f98b28a4",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Choosing binary cross_entropy and sigmoid seems to result in similar if not worse results than with softmax and cross_entropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BME342 Env",
   "language": "python",
   "name": "bme342_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
